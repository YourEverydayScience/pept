<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>pept.tracking.peptml.peptml API documentation</title>
<meta name="description" content="The *peptml* module implements a hierarchical density-based clustering
algorithm for general Positron Emission Particle Tracking (PEPT) â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pept.tracking.peptml.peptml</code></h1>
</header>
<section id="section-intro">
<p>The <em>peptml</em> module implements a hierarchical density-based clustering
algorithm for general Positron Emission Particle Tracking (PEPT)</p>
<p>The module aims to provide general classes which can
then be used in a script file as the user sees fit. For example scripts,
look at the base of the pept library.</p>
<p>The peptml subpackage accepts any instace of the LineData base class
and can create matplotlib- or plotly-based figures.</p>
<p>PEPTanalysis requires the following packages:</p>
<ul>
<li><strong>numpy</strong></li>
<li><strong>joblib</strong> for multithreaded operations (such as midpoints-finding)</li>
<li><strong>tqdm</strong> for showing progress bars</li>
<li><strong>plotly.subplots</strong> and <strong>plotly.graph_objects</strong> for plotly-based plotting</li>
<li><strong>hdbscan</strong> for clustering midpoints and centres</li>
<li><strong>time</strong> for verbose timing of operations</li>
</ul>
<p>It was successfuly used at the University of Birmingham to analyse real
Fluorine-18 tracers in air.</p>
<p>If you use this package, you should cite
the following paper: [TODO: paper signature].</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">#!/usr/bin/env python3
# -*- coding: utf-8 -*-


#    pept is a Python library that unifies Positron Emission Particle
#    Tracking (PEPT) research, including tracking, simulation, data analysis
#    and visualisation tools
#
#    Copyright (C) 2019 Andrei Leonard Nicusan
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.


# File   : peptml.py
# License: License: GNU v3.0
# Author : Andrei Leonard Nicusan &lt;a.l.nicusan@bham.ac.uk&gt;
# Date   : 28.08.2019


&#39;&#39;&#39;The *peptml* module implements a hierarchical density-based clustering
algorithm for general Positron Emission Particle Tracking (PEPT)

The module aims to provide general classes which can
then be used in a script file as the user sees fit. For example scripts,
look at the base of the pept library.

The peptml subpackage accepts any instace of the LineData base class
and can create matplotlib- or plotly-based figures.

PEPTanalysis requires the following packages:

* **numpy**
* **joblib** for multithreaded operations (such as midpoints-finding)
* **tqdm** for showing progress bars
* **plotly.subplots** and **plotly.graph_objects** for plotly-based plotting
* **hdbscan** for clustering midpoints and centres
* **time** for verbose timing of operations

It was successfuly used at the University of Birmingham to analyse real
Fluorine-18 tracers in air.

If you use this package, you should cite
the following paper: [TODO: paper signature].

&#39;&#39;&#39;


import  time
import  sys

import  numpy                                   as          np
from    scipy.spatial                           import      cKDTree

from    joblib                                  import      Parallel,       delayed
from    tqdm                                    import      tqdm
from    plotly.subplots                         import      make_subplots
import  plotly.graph_objects                    as          go

# Fix a deprecation warning inside the sklearn library
try:
    sys.modules[&#39;sklearn.externals.six&#39;] = __import__(&#39;six&#39;)
    sys.modules[&#39;sklearn.externals.joblib&#39;] = __import__(&#39;joblib&#39;)
    import hdbscan
except ImportError:
    import hdbscan

import  pept
from    .extensions.find_cutpoints_api          import      find_cutpoints_api




class Cutpoints(pept.PointData):

    def __init__(self):

        # Call pept.PointData constructor with dummy data
        super().__init__([[0., 0., 0., 0.]],
                         sample_size = 0,
                         overlap = 0,
                         verbose = False)


    @staticmethod
    def get_cutoffs(sample):

        # Check sample has shape (N, 7)
        if sample.ndim != 2 or sample.shape[1] != 7:
            raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

        # Compute cutoffs for cutpoints as the (min, max) values of the lines
        # Minimum value of the two points that define a line
        min_x = min(sample[:, 1].min(),
                    sample[:, 4].min())
        # Maximum value of the two points that define a line
        max_x = max(sample[:, 1].max(),
                    sample[:, 4].max())

        # Minimum value of the two points that define a line
        min_y = min(sample[:, 2].min(),
                    sample[:, 5].min())
        # Maximum value of the two points that define a line
        max_y = max(sample[:, 2].max(),
                    sample[:, 5].max())

        # Minimum value of the two points that define a line
        min_z = min(sample[:, 3].min(),
                    sample[:, 6].min())
        # Maximum value of the two points that define a line
        max_z = max(sample[:, 3].max(),
                    sample[:, 6].max())

        cutoffs = np.array([min_x, max_x, min_y, max_y, min_z, max_z])
        return cutoffs


    @staticmethod
    def find_cutpoints_sample(sample, max_distance, cutoffs = None):

        # Check sample has shape (N, 7)
        if sample.ndim != 2 or sample.shape[1] != 7:
            raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

        if cutoffs is None:
            cutoffs = Cutpoints.get_cutoffs(sample)
        else:
            cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
            if cutoffs.ndim != 1 or len(cutoffs) != 6:
                raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

        sample_cutpoints = find_cutpoints_api(sample, max_distance, cutoffs)
        return sample_cutpoints


    def find_cutpoints(self,
                       line_data,
                       max_distance,
                       cutoffs = None,
                       verbose = True):

        if verbose:
            start = time.time()

        # Check line_data is an instance (or a subclass!) of pept.LineData
        if not isinstance(line_data, pept.LineData):
            raise Exception(&#39;[ERROR]: line_data should be an instance of pept.LineData&#39;)

        # If cutoffs were not supplied, compute them
        if cutoffs is None:
            cutoffs = self.get_cutoffs(line_data.line_data)
        # Otherwise make sure they are a C-contiguous numpy array
        else:
            cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
            if cutoffs.ndim != 1 or len(cutoffs) != 6:
                raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

        # Using joblib, collect the cutpoints from every sample in a list
        # of arrays
        cutpoints = Parallel(n_jobs = -1, prefer = &#39;threads&#39;)(delayed(self.find_cutpoints_sample)(sample, max_distance, cutoffs) for sample in tqdm(line_data))

        # cutpoints shape: (n, m, 4), where n is the number of samples, and
        # m is the number of cutpoints in the sample
        cutpoints = np.array(cutpoints)

        number_of_samples = len(cutpoints)
        cutpoints = np.vstack(np.array(cutpoints))
        number_of_cutpoints = len(cutpoints)

        # Average number of cutpoints per sample
        cutpoints_per_sample = int(number_of_cutpoints / number_of_samples)

        super().__init__(cutpoints,
                         sample_size = cutpoints_per_sample,
                         overlap = 0,
                         verbose = False)

        if verbose:
            end = time.time()
            print(&#34;\n\n\nFinding the cutpoints took {} seconds&#34;.format(end - start))

        return self




def findMeanError(truePositions, foundPositions):

    tree = cKDTree(truePositions)

    meanError = 0
    meanErrorX = 0
    meanErrorY = 0
    meanErrorZ = 0
    n = 0
    for centre in foundPositions:
        d, index = tree.query(centre, k = 1,  n_jobs = -1)
        meanError += np.linalg.norm(centre - truePositions[index])

        meanErrorX += np.abs(centre[0] - truePositions[index][0])
        meanErrorY += np.abs(centre[1] - truePositions[index][1])
        meanErrorZ += np.abs(centre[2] - truePositions[index][2])

        n += 1

    meanError /= n

    meanErrorX /= n
    meanErrorY /= n
    meanErrorZ /= n

    return [meanError, meanErrorX, meanErrorY, meanErrorZ]




class ClustererBase:
    &#39;&#39;&#39;
    Base class that provides common functionality between any clustering algorithms.
    Any clustering algorithm should have at least the following attributes:

        sample:     the points that will be clustered
                    sample row: [time, X, Y, Z]

        labels:     a vector of size len(sample) that saves the labels of each
                    datapoint in the sample

        maxLabel:   the largest value in the labels attribute
    &#39;&#39;&#39;


    def getLabels(self):
        return self.labels


    def getSampleLabels(self):
        # Return all points as arrays of points with same label
        sampleLabels = []

        # First noise
        sampleLabels.append(self.sample[self.labels == -1])

        # Then actual labels
        for i in range(0, self.maxLabel + 1):
            sampleLabels.append(self.sample[self.labels == i])

        return np.array(sampleLabels)


    def getCentres(self):
        # the centre of a cluster is the average of the time, x, y, z columns
        # and the number of points of that cluster
        # centres row: [time, x, y, z, clusterSize]
        centres = []
        for i in range(0, self.maxLabel + 1):
            # Average time, x, y, z of cluster of label i
            centresRow = np.mean(self.sample[self.labels == i], axis = 0)
            # Append the number of points of label i
            centresRow = np.append(centresRow, (self.labels == i).sum())
            centres.append(centresRow)

        return np.array(centres)


    def plotSampleLabels(self, ax):

        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i]
            ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], alpha = 0.6, marker = &#39;1&#39;, s = 1)

        # Plot noise
        dataPointsLabel = self.sample[self.labels == -1]
        ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], c = &#39;k&#39;, alpha = 0.1, marker = &#39;.&#39;, s = 1)


    def plotSampleLabelsAltAxes(self, ax):

        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i]
            ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], alpha = 0.6, marker = &#39;1&#39;, s = 1)

        # Plot noise
        dataPointsLabel = self.sample[self.labels == -1]
        ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], c = &#39;k&#39;, alpha = 0.01, marker = &#39;.&#39;, s = 1)


    def plotCentres(self, ax):

        centres = self.getCentres()
        if len(centres) &gt; 0:
            ax.scatter(centres[:, 1], centres[:, 2], centres[:, 3], c = &#39;r&#39;, marker = &#39;D&#39;, s = 1)


    def plotCentresAltAxes(self, ax):

        centres = self.getCentres()
        if len(centres) &gt; 0:
            ax.scatter(centres[:, 3], centres[:, 1], centres[:, 2], c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def getSampleLabelsTraces(self, noise = True):
        traces = []
        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i][0::10]
            traces.append(go.Scatter3d(
                x = dataPointsLabel[:, 1],
                y = dataPointsLabel[:, 2],
                z = dataPointsLabel[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = 2,
                    opacity = 0.8,
                    colorscale = &#39;Cividis&#39;
                )
            ))

        if noise == True:
            # Noise points
            dataPointsLabel = self.sample[self.labels == -1][0::10]
            traces.append(go.Scatter3d(
                x = dataPointsLabel[:, 1],
                y = dataPointsLabel[:, 2],
                z = dataPointsLabel[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = 1,
                    opacity = 0.4,
                    color = &#39;black&#39;
                )
            ))

        return traces


    def getCentresTrace(self):
        centres = self.getCentres()
        color = centres[:, -1]
        color = color[[0, len(color) // 2, -1]]
        trace = go.Scatter3d(
            x=centres[:, 1],
            y=centres[:, 2],
            z=centres[:, 3],
            mode=&#39;markers&#39;,
            marker=dict(
                size=2,
                color=color,   # set color to sample size
                colorscale=&#39;Cividis&#39;,   # choose a colorscale
                colorbar=dict(
                    title=&#34;Number of clustered points&#34;
                ),
                opacity=0.5
            )
        )

        return trace




class HDBSCANClusterer:

    def __init__(self,
                 min_cluster_size = 5,
                 min_samples = None,
                 allow_single_cluster = False):

        if 0 &lt; min_cluster_size &lt; 2:
            print(&#34;\n[WARNING]: min_cluster_size was set to 2, as it was {} &lt; 2\n&#34;.format(min_cluster_size))
            min_cluster_size = 2

        self.clusterer = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,
                                         min_samples = min_samples,
                                         core_dist_n_jobs = -1,
                                         allow_single_cluster = allow_single_cluster)

        &#39;&#39;&#39;
        # Call pept.PointData constructor with dummy data
        super().__init__([[0., 0., 0., 0.]],
                         sample_size = 0,
                         overlap = 0,
                         verbose = False)
        &#39;&#39;&#39;


    @property
    def min_cluster_size(self):
        return self.clusterer.min_cluster_size


    @min_cluster_size.setter
    def min_cluster_size(self, new_min_cluster_size):
        self.clusterer.min_cluster_size = new_min_cluster_size


    @property
    def min_samples(self):
        return self.clusterer.min_cluster_size


    @min_samples.setter
    def min_samples(self, new_min_samples):
        self.clusterer.min_samples = new_min_samples


    @property
    def allow_single_cluster(self):
        return self.clusterer.allow_single_cluster


    @allow_single_cluster.setter
    def allow_single_cluster(self, option):
        self.clusterer.allow_single_cluster = option


    def fit_sample(self,
                   sample,
                   store_labels = False,
                   noise = False,
                   as_array = False,
                   verbose = False):

        if verbose:
            start = time.time()

        # sample row: [time, x, y, z]
        if sample.ndim != 2 or sample.shape[1] &lt; 4:
            raise ValueError(&#39;\n[ERROR]: sample should have two dimensions (M, N), where N &gt;= 4. Received {}\n&#39;.format(sample.shape))

        # Only cluster based on [x, y, z]
        labels = self.clusterer.fit_predict(sample[:, 1:4])
        max_label = labels.max()

        centres = []
        clustered_cutpoints = []

        # the centre of a cluster is the average of the time, x, y, z columns
        # and the number of points of that cluster
        # centres row: [time, x, y, z, ..etc.., cluster_size]
        centres = []
        for i in range(0, max_label + 1):
            # Average time, x, y, z of cluster of label i
            centres_row = np.mean(sample[labels == i], axis = 0)
            # Append the number of points of label i =&gt; cluster_size
            centres_row = np.append(centres_row, (labels == i).sum())
            centres.append(centres_row)

        centres = np.array(centres)

        if not as_array:
            centres = pept.PointData(centres,
                                     sample_size = 0,
                                     overlap = 0,
                                     verbose = False)

        # Return all cutpoints as a list of numpy arrays for every label
        # where the last column of an array is the label
        if store_labels:
            # Create a list of numpy arrays with rows: [t, x, y, z, ..etc.., label]
            if noise:
                cutpoints = sample[labels == -1]
                cutpoints = np.insert(cutpoints, cutpoints.shape[1], -1, axis = 1)
                clustered_cutpoints.append(cutpoints)

            for i in range(0, max_label + 1):
                cutpoints = sample[labels == i]
                cutpoints = np.insert(cutpoints, cutpoints.shape[1], i, axis = 1)
                clustered_cutpoints.append(cutpoints)

            clustered_cutpoints = np.vstack(np.array(clustered_cutpoints))

            if not as_array:
                clustered_cutpoints = pept.PointData(clustered_cutpoints,
                                                     sample_size = 0,
                                                     overlap = 0,
                                                     verbose = False)

        if verbose:
            end = time.time()
            print(&#34;Fitting one sample took {} seconds&#34;.format(end - start))

        return [centres, clustered_cutpoints]


    def fit_cutpoints(self,
                      cutpoints,
                      store_labels = False,
                      noise = False,
                      verbose = True):

        if verbose:
            start = time.time()

        if not isinstance(cutpoints, pept.PointData):
            raise Exception(&#39;[ERROR]: cutpoints should be an instance of pept.PointData (or any class inheriting from it)&#39;)

        # Fit all samples in `cutpoints` in parallel using joblib
        # Collect all outputs as a list
        data_list = Parallel(n_jobs = -1)(delayed(self.fit_sample)(sample,
                                                store_labels = store_labels,
                                                noise = noise,
                                                as_array = True) for sample in tqdm(cutpoints))

        # Access joblib.Parallel output as list comprehensions
        centres = np.array([row[0] for row in data_list if len(row[0]) != 0])
        if len(centres) != 0:
            centres = pept.PointData(np.vstack(centres),
                                     sample_size = 0,
                                     overlap = 0,
                                     verbose = False)

        if store_labels:
            clustered_cutpoints = np.array([row[1] for row in data_list if len(row[1]) != 0])
            clustered_cutpoints = pept.PointData(np.vstack(np.array(clustered_cutpoints)),
                                                 sample_size = 0,
                                                 overlap = 0,
                                                 verbose = False)

        if verbose:
            end = time.time()
            print(&#34;Fitting cutpoints took {} seconds&#34;.format(end - start))

        if store_labels:
            return [centres, clustered_cutpoints]
        else:
            return [centres, []]




    def fitSampleParallel(self, sample, saveLabels = False, saveNoise = False):
        # Function that will be parallelised
        # Needs to return a list of the needed outputs
        self.fitSample(sample)
        centres = self.getCentres()

        if saveLabels:
            sampleLabelsTraces = self.getSampleLabelsTraces(noise = saveNoise)
        else:
            sampleLabelsTraces = []

        return [centres, sampleLabelsTraces]


    def clusterIterable(self,
                        samples,
                        saveLabels = False,
                        saveNoise = False):

        # Call joblib Parallel subroutine for every sample needed
        # Collects returned data as a list of outputs
        dataList = Parallel(n_jobs = -1)(delayed(self.fitSampleParallel)(sample, saveLabels, saveNoise) for sample in tqdm(samples))

        # Access the output from the parallelised function as list comprehensions
        # centres row: [time, x, y, z, meanMidpointsClusterSize]
        self.centres = np.array([dataRow[0] for dataRow in dataList if len(dataRow[0]) != 0])
        if len(self.centres) != 0:
            self.centres = np.vstack(self.centres)

        # Collect all the lists of clustered midpoints traces and flatten them
        # Plot the midpoints only if plotMidpoints == True
        if saveLabels:
            self.labelsTraces = [dataRow[1] for dataRow in dataList]
            self.labelsTraces = [elem for sublist in self.labelsTraces for elem in sublist]

            return [self.centres, self.labelsTraces]
        else:
            return [self.centres, []]




class HDBSCANclustererAuto(ClustererBase):
    &#39;&#39;&#39;
    Automatically vary the harshness of an HDBSCAN clusterer until
    a particle has been found
    &#39;&#39;&#39;

    def __init__(self, sampleSize, k = [0.001, 0.8], nIter = 5):
        # sampleSize is the average number of points per particle

        # k is a correction factor ranging from 0 to 1, having the
        # physical meaning of the minimum ratio of points that
        # need to be part of the cluster.
        #   eg. k = 1 means all points need to be close together =&gt; harsher
        #       k = 0.2 means 20% of points need to be close =&gt; more lenient
        self.sampleSize = sampleSize
        self.k = k
        self.nIter = nIter

        if self.sampleSize &lt;= 0:
            raise Exception(&#39;[ERROR]: sampleSize needs to be a positive integer&#39;)

        # Create a list of clusterers with min_cluster_size ranging from min to max, with
        # nIter maximum iterations to find a centre

        self.autoClusterer = []

        # lenient because smaller minimum cluster size =&gt; more points into cluster
        min_min_cluster_size = k[0] * self.sampleSize #self.sampleSize / 30#10

        # harsh
        max_min_cluster_size = k[1] * self.sampleSize #self.sampleSize / 20#5

        # from harsh to lenient
        sizes = np.linspace(max_min_cluster_size, min_min_cluster_size, self.nIter)

        for min_cluster_size in sizes:
            min_cluster_size = int(min_cluster_size)
            if min_cluster_size &lt; 2:
                min_cluster_size = 2
            self.autoClusterer.append(hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,
                                                      core_dist_n_jobs = -1))


    def changeParameters(self, sampleSize = 0, nIter = 5):
        if sampleSize != 0:
            if self.sampleSize &lt;= 0 or type(sampleSize) != int:
                raise Exception(&#39;[ERROR]: sampleSize needs to be a positive integer&#39;)
            else:
                self.sampleSize = sampleSize

        self.nIter = nIter

        if self.sampleSize != 0:
            # Create a list of clusterers with min_cluster_size ranging from min to max, with
            # nIter maximum iterations to find a centre

            self.autoClusterer = []

            # lenient because smaller minimum cluster size =&gt; more points into cluster
            min_min_cluster_size = self.sampleSize / 10

            # harsh
            max_min_cluster_size = self.sampleSize / 5

            # from harsh to lenient
            sizes = np.linspace(max_min_cluster_size, min_min_cluster_size, self.nIter)

            for min_cluster_size in sizes:
                self.autoClusterer.append(hdbscan.HDBSCAN(min_cluster_size=int(min_cluster_size)))


    def fitSample(self, sample):
        #start = time.time()

        # sample row: [time, x, y, z]
        self.sample = sample

        for clusterer in self.autoClusterer:
            # Only cluster based on [x, y, z]
            clusterer.fit(self.sample[:, 1:4])
            self.labels = clusterer.labels_
            self.maxLabel = self.labels.max()

            # Stop when a particle was found
            if self.maxLabel &gt;= 0:
                break

        #end = time.time()
        #print(&#34;Fitting one sample took {} seconds&#34;.format(end - start))



class ClusterCentres:
    &#39;&#39;&#39;
    Helper/wrapper class that receives cluster centres and can
    yield samples of adaptive size for a second pass of clustering
    &#39;&#39;&#39;

    def __init__(self, centres, sampleSize=50, overlap=0):
        self.centres = centres
        self.numberOfCentres = len(centres)
        self.sampleSize = sampleSize
        self.overlap = overlap

        self._index = 0


    def getNumberOfSamples(self):
        if self.numberOfCentres &gt;= self.sampleSize:
            return (self.numberOfCentres - self.sampleSize) // (self.sampleSize - self.overlap) + 1
        else:
            return 0


    def getCentresSampleN(self, sampleN):
        if (sampleN &gt; self.getNumberOfSamples()) or sampleN &lt;= 0:
            raise Exception(&#34;\n\n[ERROR]: Trying to access a non-existent sample: asked for sample number {}, when there are {} samples\n&#34;.format(sampleN, self.getNumberOfSamples()))

        startIndex = (sampleN - 1) * (self.sampleSize - self.overlap)
        return self.centres[startIndex:(startIndex + self.sampleSize)]


    def __len__(self):
        return self.getNumberOfSamples()


    def __iter__(self):
        return self


    def __next__(self):
        # sampleSize &gt; 0 =&gt; return slices
        if self._index != 0:
            self._index = self._index + self.sampleSize - self.overlap
        else:
            self._index = self._index + self.sampleSize


        if self._index &gt; self.numberOfCentres:
            self._index = 0
            raise StopIteration

        return self.centres[(self._index - self.sampleSize):self._index]




class HDBSCANtwoPassClusterer:
    &#39;&#39;&#39;
    Helper class which implements a second pass of clustering
    over the centres found by &#39;clusterer&#39;

    Two-pass clustering helps with spatial resolution and
    determining the trajectory of a moving particle

        clusterer: a clusterer which has the method fitSample(sample) that will
            fit samples of midpoints (first-pass clustering)

        clusterer2: a clusterer which has the method fitSample(sample) that will
            fit samples of centres (second-pass clustering)

        samplesMidpoints: an array of samples of midpoints.
            samplesMidpoints.shape: (numberOfSamples, numberOfMidpointsPerSample, 4)
            (can alternatively send a Midpoints instance which can be iterated over)

        centresSampleSize: number of centres to send per sample  to the second reclustering
    &#39;&#39;&#39;

    def __init__(self, clusterer, clusterer2, samplesMidpoints, centresSampleSize, centresOverlap=0):
        # clusterer is an instance which has the method .fitSample(sample)
        # samplesMidpoints is an array of samples of midpoints
        # samplesMidpoints.shape: (numberOfSamples, numberOfMidpointsPerSample, 4)
        # (can alternatively send a Midpoints instance which can be iterated over)

        self.clusterer = clusterer
        self.clusterer2 = clusterer2
        self.samplesMidpoints = samplesMidpoints
        self.centresSampleSize = centresSampleSize
        self.centresOverlap = centresOverlap
        self.centres = []
        self.centres2 = []


    def fit(self):

        start = time.time()
        # First pass of clustering for midpoints
        for sample in self.samplesMidpoints:
            self.clusterer.fitSample(sample)
            newCentres = self.clusterer.getCentres()
            self.centres.extend(newCentres)

        end = time.time()
        print(&#39;First pass of clustering took {} s&#39;.format(end - start))

        # centres row: [time, x, y, z, clusterSize]
        self.centres = np.array(self.centres)

        self.samplesCentres = ClusterCentres(self.centres, self.centresSampleSize, self.centresOverlap)

        print(&#39;Total number of samples of centres: {}&#39;.format(self.samplesCentres.getNumberOfSamples()))

        start = time.time()
        # Second pass of clustering for centres
        for sample in self.samplesCentres:
            self.clusterer2.fitSample(sample)
            newCentres = self.clusterer2.getCentres()
            self.centres2.extend(newCentres)

        end = time.time()
        print(&#39;Second pass of clustering took {} s&#39;.format(end - start))

        # centres2 row: [time, x, y, z, meanCentresClusterSize, clusterSize]
        self.centres2 = np.array(self.centres2)


    def getCentres(self):
        return self.centres


    def getCentres2(self):
        return self.centres2


    def plotCentres(self, ax):

        if len(self.centres) &gt; 0:
            ax.scatter(self.centres[:, 1], self.centres[:, 2], self.centres[:, 3],
                    c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentresAltAxes(self, ax):

        if len(self.centres) &gt; 0:
            ax.scatter(self.centres[:, 3], self.centres[:, 1], self.centres[:, 2],
                    c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentres2(self, ax):

        if len(self.centres2) &gt; 0:
            ax.scatter(self.centres2[:, 1], self.centres2[:, 2], self.centres2[:, 3],
                    c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentres2AltAxes(self, ax):

        if len(self.centres2) &gt; 0:
            ax.scatter(self.centres2[:, 3], self.centres2[:, 1], self.centres2[:, 2],
                    c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)




class TrajectorySeparation:

    def __init__(self, centres, pointsToCheck = 25, maxDistance = 20, maxClusterDiff = 500):
        # centres row: [time, x, y, z, clusterSize]
        # Make sure the trajectory is memory-contiguous for efficient
        # KDTree partitioning
        self.centres = np.ascontiguousarray(centres)
        self.pointsToCheck = pointsToCheck
        self.maxDistance = maxDistance
        self.maxClusterDiff = maxClusterDiff

        # For every point in centres, save a set of the trajectory
        # indices of the trajectories that they are part of
        #   eg. centres[2] is part of trajectories 0 and 1 =&gt;
        #   trajectoryIndices[2] = {0, 1}
        # Initialise a vector of empty sets of size len(centres)
        self.trajectoryIndices = np.array([ set() for i in range(len(self.centres)) ])

        # For every trajectory found, save a list of the indices of
        # the centres that are part of that trajectory
        #   eg. trajectory 1 is comprised of centres 3, 5 and 8 =&gt;
        #   centresIndices[1] = [3, 5, 8]
        self.centresIndices = [[]]

        # Maximum trajectory index
        self.maxIndex = 0


    def findTrajectories(self):

        for i, currentPoint in enumerate(self.centres):

            if i == 0:
                # Add the first point to trajectory 0
                self.trajectoryIndices[0].add(self.maxIndex)
                self.centresIndices[self.maxIndex].append(0)
                self.maxIndex += 1
                continue

            # Search for the closest previous pointsToCheck points
            # within a given maxDistance
            startIndex = i - self.pointsToCheck
            endIndex = i

            if startIndex &lt; 0:
                startIndex = 0

            # Construct a KDTree from the x, y, z (1:4) of the
            # selected points. Get the indices for all the points within
            # maxDistance of the currentPoint
            tree = cKDTree(self.centres[startIndex:endIndex, 1:4])
            closestIndices = tree.query_ball_point(currentPoint[1:4], self.maxDistance, n_jobs=-1)
            closestIndices = np.array(closestIndices) + startIndex

            # If no point was found, it is a new trajectory. Continue
            if len(closestIndices) == 0:
                self.trajectoryIndices[i].add(self.maxIndex)
                self.centresIndices.append([i])
                self.maxIndex += 1
                continue

            # For every close point found, search for all the trajectory indices
            #   - If all trajectory indices sets are equal and of a single value
            #   then currentPoint is part of the same trajectory
            #   - If all trajectory indices sets are equal, but of more values,
            #   then currentPoint diverged from an intersection of trajectories
            #   and is part of a single trajectory =&gt; separate it
            #
            #   - If every pair of trajectory indices sets is not disjoint, then
            #   currentPoint is only one of them
            #   - If there exists a pair of trajectory indices sets that is
            #   disjoint, then currentPoint is part of all of them

            # Select the trajectories of all the points that were found
            # to be the closest
            closestTrajectories = self.trajectoryIndices[closestIndices]
            #print(&#34;closestTrajectories:&#34;)
            #print(closestTrajectories)

            # If all the closest points are part of the same trajectory
            # (just one!), then the currentPoint is part of it too
            if (np.all(closestTrajectories == closestTrajectories[0]) and
                len(closestTrajectories[0]) == 1):

                self.trajectoryIndices[i] = closestTrajectories[0]
                self.centresIndices[ next(iter(closestTrajectories[0])) ].append(i)
                continue

            # Otherwise, check the points based on their cluster size
            else:
                # Create a list of all the trajectories that were found to
                # intersect
                #print(&#39;\nIntersection:&#39;)
                closestTrajIndices = list( set().union(*closestTrajectories) )

                #print(&#34;ClosestTrajIndices:&#34;)
                #print(closestTrajIndices)

                # For each close trajectory, calculate the mean cluster size
                # of the last lastPoints points
                lastPoints = 50

                # Keep track of the mean cluster size that is the closest to
                # the currentPoint&#39;s clusterSize
                currentClusterSize = currentPoint[4]
                #print(&#34;currentClusterSize = {}&#34;.format(currentClusterSize))
                closestTrajIndex = -1
                clusterSizeDiff = self.maxClusterDiff

                for trajIndex in closestTrajIndices:
                    #print(&#34;trajIndex = {}&#34;.format(trajIndex))

                    trajCentres = self.centres[ self.centresIndices[trajIndex] ]
                    #print(&#34;trajCentres:&#34;)
                    #print(trajCentres)
                    meanClusterSize = trajCentres[-lastPoints:][:, 4].mean()
                    #print(&#34;meanClusterSize = {}&#34;.format(meanClusterSize))
                    #print(&#34;clusterSizeDiff = {}&#34;.format(clusterSizeDiff))
                    #print(&#34;abs diff = {}&#34;.format(np.abs( currentClusterSize - meanClusterSize )))
                    if np.abs( currentClusterSize - meanClusterSize ) &lt; clusterSizeDiff:
                        closestTrajIndex = trajIndex
                        clusterSizeDiff = np.abs( currentClusterSize - meanClusterSize )

                if closestTrajIndex == -1:
                    #self.trajectoryIndices[i] = set(closestTrajIndices)
                    #for trajIndex in closestTrajIndices:
                    #    self.centresIndices[trajIndex].append(i)

                    print(&#34;\n**** -1 ****\n&#34;)
                    break
                else:
                    #print(&#34;ClosestTrajIndex found = {}&#34;.format(closestTrajIndex))
                    self.trajectoryIndices[i] = set([closestTrajIndex])
                    self.centresIndices[closestTrajIndex].append(i)




            &#39;&#39;&#39;
            # If the current point is not part of any trajectory, assign it
            # the maxIndex and increment it
            if len(self.trajectoryIndices[i]) == 0:
                self.trajectoryIndices[i].append(self.maxIndex)
                self.maxIndex += 1

            print(self.trajectoryIndices[i])
            print(self.maxIndex)

            # Construct a KDTree from the numberOfPoints in front of
            # the current point
            tree = cKDTree(self.trajectory[(i + 1):(i + self.numberOfPoints + 2)][1:4])

            # For every trajectory that the current point is part of,
            # find the closest points in front of it
            numberOfIntersections = len(self.trajectoryIndices[i])
            dist, nextPointsIndices = tree.query(currentPoint, k=numberOfIntersections, distance_upper_bound=self.maxDistance, n_jobs=-1)

            print(nextPointsIndices)

            # If the current point is part of more trajectories,
            # an intersection happened. Call subroutine to part
            # the trajectories
            if numberOfIntersections &gt; 1:
                for j in range(0, len(self.trajectoryIndices[i])):
                    trajIndex = self.trajectoryIndices[i][j]
                    self.trajectoryIndices[i + 1 + nextPointsIndices[j]].append(trajIndex)

            else:
                self.trajectoryIndices[i + 1 + nextPointsIndices].append(self.trajectoryIndices[i][0])

            print(self.trajectoryIndices)
            &#39;&#39;&#39;


    def getTrajectories(self):

        self.individualTrajectories = []
        for trajCentres in self.centresIndices:
            self.individualTrajectories.append(self.centres[trajCentres])

        self.individualTrajectories = np.array(self.individualTrajectories)
        return self.individualTrajectories

        &#39;&#39;&#39;
        self.individualTrajectories = [ [] for i in range(0, self.maxIndex + 1) ]
        for i in range(0, len(self.trajectoryIndices)):
            for trajIndex in self.trajectoryIndices[i]:
                self.individualTrajectories[trajIndex].append(self.centres[i])

        self.individualTrajectories = np.array(self.individualTrajectories)
        for i in range(len(self.individualTrajectories)):
            if len(self.individualTrajectories[i]) &gt; 0:
                self.individualTrajectories[i] = np.vstack(self.individualTrajectories[i])
        return self.individualTrajectories
        &#39;&#39;&#39;


    def plotTrajectoriesAltAxes(self, ax):
        trajectories = self.getTrajectories()
        for traj in trajectories:
            if len(traj) &gt; 0:
                ax.scatter(traj[:, 3], traj[:, 1], traj[:, 2], marker=&#39;D&#39;, s=10)




class PlotlyGrapher:
    # Helper class that automatically generates Plotly graphs
    # for the PEPT data

    def __init__(self, rows=1, cols=1, xlim = [0, 500],
                 ylim = [0, 500], zlim = [0, 712], subplot_titles = [&#39;  &#39;]):
        self.rows = rows
        self.cols = cols

        self.xlim = xlim
        self.ylim = ylim
        self.zlim = zlim

        self.subplot_titles = subplot_titles
        self.subplot_titles.extend([&#39;  &#39;] * (rows * cols - len(subplot_titles)))


    def createFigure(self):
        # Create subplots and set limits

        specs = [[{&#34;type&#34;: &#34;scatter3d&#34;}] * self.cols] * self.rows

        self.fig = make_subplots(rows = self.rows, cols = self.cols,
                    specs = specs, subplot_titles = self.subplot_titles,
                    horizontal_spacing = 0.005, vertical_spacing = 0.05)

        self.fig[&#39;layout&#39;].update(margin = dict(l=0,r=0,b=30,t=30), showlegend = False)

        # For every subplot (scene), set axes&#39; ratios and limits
        # Also set the y axis to point upwards
        # Plotly naming convention of scenes: &#39;scene&#39;, &#39;scene2&#39;, etc.
        for i in range(self.rows):
            for j in range(self.cols):
                if i == j == 0:
                    scene = &#39;scene&#39;
                else:
                    scene = &#39;scene{}&#39;.format(i * self.cols + j + 1)

                # Justify subplot title on the left
                self.fig.layout.annotations[i * self.cols + j].update(x = (j + 0.08) / self.cols)
                self.fig[&#39;layout&#39;][scene].update(aspectmode = &#39;manual&#39;,
                                                 aspectratio = {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1},
                                                 camera = {&#39;up&#39;: {&#39;x&#39;: 0, &#39;y&#39;: 1, &#39;z&#39;:0},
                                                           &#39;eye&#39;: {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1}},
                                                 xaxis = {&#39;range&#39;: self.xlim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;x&lt;/i&gt; (mm)&#34;}},
                                                 yaxis = {&#39;range&#39;: self.ylim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;y&lt;/i&gt; (mm)&#34;}},
                                                 zaxis = {&#39;range&#39;: self.zlim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;z&lt;/i&gt; (mm)&#34;}}
                                                 )

        return self.fig


    def getFigure(self):
        return self.fig


    def addDataAsTrace(self, data, row, col, size = 2, color = None):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            trace = go.Scatter3d(
                x = data[:, 1],
                y = data[:, 2],
                z = data[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = size,
                    color = color,
                    opacity = 0.8
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addDataAsTraceColorbar(self, data, row, col, titleColorbar = None, size = 3):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            if titleColorbar != None:
                colorbar=dict(title=titleColorbar)
            else:
                colorbar = dict()

            trace = go.Scatter3d(
                x=data[:, 1],
                y=data[:, 2],
                z=data[:, 3],
                mode=&#39;markers&#39;,
                marker=dict(
                    size=size,
                    color=data[:, -1],   # set color to sample size
                    colorscale=&#39;Magma&#39;,     # choose a colorscale
                    colorbar=colorbar,
                    opacity=0.8
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addDataAsTraceLine(self, data, row, col):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            trace = go.Scatter3d(
                x=data[:, 1],
                y=data[:, 2],
                z=data[:, 3],
                mode=&#39;lines&#39;,
                line=dict(
                    width=4,
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addTrace(self, trace, row, col):
        # Add precomputed trace
        # Can accept HDBSCANclusterer.getCentresTrace() output
        if len(trace) != 0:
            self.fig.add_traces(trace, rows=row, cols=col)


    def addTraces(self, traces, row, col):
        # Add precomputed traces
        # Can accept HDBSCANclusterer.getSampleLabelsTraces() output
        if len(traces) != 0:
            self.fig.add_traces(traces, rows=[row]*len(traces), cols=[col]*len(traces))


    def showFigure(self):
        self.fig.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pept.tracking.peptml.peptml.findMeanError"><code class="name flex">
<span>def <span class="ident">findMeanError</span></span>(<span>truePositions, foundPositions)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def findMeanError(truePositions, foundPositions):

    tree = cKDTree(truePositions)

    meanError = 0
    meanErrorX = 0
    meanErrorY = 0
    meanErrorZ = 0
    n = 0
    for centre in foundPositions:
        d, index = tree.query(centre, k = 1,  n_jobs = -1)
        meanError += np.linalg.norm(centre - truePositions[index])

        meanErrorX += np.abs(centre[0] - truePositions[index][0])
        meanErrorY += np.abs(centre[1] - truePositions[index][1])
        meanErrorZ += np.abs(centre[2] - truePositions[index][2])

        n += 1

    meanError /= n

    meanErrorX /= n
    meanErrorY /= n
    meanErrorZ /= n

    return [meanError, meanErrorX, meanErrorY, meanErrorZ]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pept.tracking.peptml.peptml.ClusterCentres"><code class="flex name class">
<span>class <span class="ident">ClusterCentres</span></span>
<span>(</span><span>centres, sampleSize=50, overlap=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Helper/wrapper class that receives cluster centres and can
yield samples of adaptive size for a second pass of clustering</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class ClusterCentres:
    &#39;&#39;&#39;
    Helper/wrapper class that receives cluster centres and can
    yield samples of adaptive size for a second pass of clustering
    &#39;&#39;&#39;

    def __init__(self, centres, sampleSize=50, overlap=0):
        self.centres = centres
        self.numberOfCentres = len(centres)
        self.sampleSize = sampleSize
        self.overlap = overlap

        self._index = 0


    def getNumberOfSamples(self):
        if self.numberOfCentres &gt;= self.sampleSize:
            return (self.numberOfCentres - self.sampleSize) // (self.sampleSize - self.overlap) + 1
        else:
            return 0


    def getCentresSampleN(self, sampleN):
        if (sampleN &gt; self.getNumberOfSamples()) or sampleN &lt;= 0:
            raise Exception(&#34;\n\n[ERROR]: Trying to access a non-existent sample: asked for sample number {}, when there are {} samples\n&#34;.format(sampleN, self.getNumberOfSamples()))

        startIndex = (sampleN - 1) * (self.sampleSize - self.overlap)
        return self.centres[startIndex:(startIndex + self.sampleSize)]


    def __len__(self):
        return self.getNumberOfSamples()


    def __iter__(self):
        return self


    def __next__(self):
        # sampleSize &gt; 0 =&gt; return slices
        if self._index != 0:
            self._index = self._index + self.sampleSize - self.overlap
        else:
            self._index = self._index + self.sampleSize


        if self._index &gt; self.numberOfCentres:
            self._index = 0
            raise StopIteration

        return self.centres[(self._index - self.sampleSize):self._index]</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.ClusterCentres.getCentresSampleN"><code class="name flex">
<span>def <span class="ident">getCentresSampleN</span></span>(<span>self, sampleN)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getCentresSampleN(self, sampleN):
    if (sampleN &gt; self.getNumberOfSamples()) or sampleN &lt;= 0:
        raise Exception(&#34;\n\n[ERROR]: Trying to access a non-existent sample: asked for sample number {}, when there are {} samples\n&#34;.format(sampleN, self.getNumberOfSamples()))

    startIndex = (sampleN - 1) * (self.sampleSize - self.overlap)
    return self.centres[startIndex:(startIndex + self.sampleSize)]</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClusterCentres.getNumberOfSamples"><code class="name flex">
<span>def <span class="ident">getNumberOfSamples</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getNumberOfSamples(self):
    if self.numberOfCentres &gt;= self.sampleSize:
        return (self.numberOfCentres - self.sampleSize) // (self.sampleSize - self.overlap) + 1
    else:
        return 0</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase"><code class="flex name class">
<span>class <span class="ident">ClustererBase</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Base class that provides common functionality between any clustering algorithms.
Any clustering algorithm should have at least the following attributes:</p>
<pre><code>sample:     the points that will be clustered
            sample row: [time, X, Y, Z]

labels:     a vector of size len(sample) that saves the labels of each
            datapoint in the sample

maxLabel:   the largest value in the labels attribute
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class ClustererBase:
    &#39;&#39;&#39;
    Base class that provides common functionality between any clustering algorithms.
    Any clustering algorithm should have at least the following attributes:

        sample:     the points that will be clustered
                    sample row: [time, X, Y, Z]

        labels:     a vector of size len(sample) that saves the labels of each
                    datapoint in the sample

        maxLabel:   the largest value in the labels attribute
    &#39;&#39;&#39;


    def getLabels(self):
        return self.labels


    def getSampleLabels(self):
        # Return all points as arrays of points with same label
        sampleLabels = []

        # First noise
        sampleLabels.append(self.sample[self.labels == -1])

        # Then actual labels
        for i in range(0, self.maxLabel + 1):
            sampleLabels.append(self.sample[self.labels == i])

        return np.array(sampleLabels)


    def getCentres(self):
        # the centre of a cluster is the average of the time, x, y, z columns
        # and the number of points of that cluster
        # centres row: [time, x, y, z, clusterSize]
        centres = []
        for i in range(0, self.maxLabel + 1):
            # Average time, x, y, z of cluster of label i
            centresRow = np.mean(self.sample[self.labels == i], axis = 0)
            # Append the number of points of label i
            centresRow = np.append(centresRow, (self.labels == i).sum())
            centres.append(centresRow)

        return np.array(centres)


    def plotSampleLabels(self, ax):

        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i]
            ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], alpha = 0.6, marker = &#39;1&#39;, s = 1)

        # Plot noise
        dataPointsLabel = self.sample[self.labels == -1]
        ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], c = &#39;k&#39;, alpha = 0.1, marker = &#39;.&#39;, s = 1)


    def plotSampleLabelsAltAxes(self, ax):

        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i]
            ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], alpha = 0.6, marker = &#39;1&#39;, s = 1)

        # Plot noise
        dataPointsLabel = self.sample[self.labels == -1]
        ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], c = &#39;k&#39;, alpha = 0.01, marker = &#39;.&#39;, s = 1)


    def plotCentres(self, ax):

        centres = self.getCentres()
        if len(centres) &gt; 0:
            ax.scatter(centres[:, 1], centres[:, 2], centres[:, 3], c = &#39;r&#39;, marker = &#39;D&#39;, s = 1)


    def plotCentresAltAxes(self, ax):

        centres = self.getCentres()
        if len(centres) &gt; 0:
            ax.scatter(centres[:, 3], centres[:, 1], centres[:, 2], c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def getSampleLabelsTraces(self, noise = True):
        traces = []
        for i in range(0, self.maxLabel + 1):
            dataPointsLabel = self.sample[self.labels == i][0::10]
            traces.append(go.Scatter3d(
                x = dataPointsLabel[:, 1],
                y = dataPointsLabel[:, 2],
                z = dataPointsLabel[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = 2,
                    opacity = 0.8,
                    colorscale = &#39;Cividis&#39;
                )
            ))

        if noise == True:
            # Noise points
            dataPointsLabel = self.sample[self.labels == -1][0::10]
            traces.append(go.Scatter3d(
                x = dataPointsLabel[:, 1],
                y = dataPointsLabel[:, 2],
                z = dataPointsLabel[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = 1,
                    opacity = 0.4,
                    color = &#39;black&#39;
                )
            ))

        return traces


    def getCentresTrace(self):
        centres = self.getCentres()
        color = centres[:, -1]
        color = color[[0, len(color) // 2, -1]]
        trace = go.Scatter3d(
            x=centres[:, 1],
            y=centres[:, 2],
            z=centres[:, 3],
            mode=&#39;markers&#39;,
            marker=dict(
                size=2,
                color=color,   # set color to sample size
                colorscale=&#39;Cividis&#39;,   # choose a colorscale
                colorbar=dict(
                    title=&#34;Number of clustered points&#34;
                ),
                opacity=0.5
            )
        )

        return trace</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pept.tracking.peptml.peptml.HDBSCANclustererAuto" href="#pept.tracking.peptml.peptml.HDBSCANclustererAuto">HDBSCANclustererAuto</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.ClustererBase.getCentres"><code class="name flex">
<span>def <span class="ident">getCentres</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getCentres(self):
    # the centre of a cluster is the average of the time, x, y, z columns
    # and the number of points of that cluster
    # centres row: [time, x, y, z, clusterSize]
    centres = []
    for i in range(0, self.maxLabel + 1):
        # Average time, x, y, z of cluster of label i
        centresRow = np.mean(self.sample[self.labels == i], axis = 0)
        # Append the number of points of label i
        centresRow = np.append(centresRow, (self.labels == i).sum())
        centres.append(centresRow)

    return np.array(centres)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.getCentresTrace"><code class="name flex">
<span>def <span class="ident">getCentresTrace</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getCentresTrace(self):
    centres = self.getCentres()
    color = centres[:, -1]
    color = color[[0, len(color) // 2, -1]]
    trace = go.Scatter3d(
        x=centres[:, 1],
        y=centres[:, 2],
        z=centres[:, 3],
        mode=&#39;markers&#39;,
        marker=dict(
            size=2,
            color=color,   # set color to sample size
            colorscale=&#39;Cividis&#39;,   # choose a colorscale
            colorbar=dict(
                title=&#34;Number of clustered points&#34;
            ),
            opacity=0.5
        )
    )

    return trace</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.getLabels"><code class="name flex">
<span>def <span class="ident">getLabels</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getLabels(self):
    return self.labels</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.getSampleLabels"><code class="name flex">
<span>def <span class="ident">getSampleLabels</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getSampleLabels(self):
    # Return all points as arrays of points with same label
    sampleLabels = []

    # First noise
    sampleLabels.append(self.sample[self.labels == -1])

    # Then actual labels
    for i in range(0, self.maxLabel + 1):
        sampleLabels.append(self.sample[self.labels == i])

    return np.array(sampleLabels)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.getSampleLabelsTraces"><code class="name flex">
<span>def <span class="ident">getSampleLabelsTraces</span></span>(<span>self, noise=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getSampleLabelsTraces(self, noise = True):
    traces = []
    for i in range(0, self.maxLabel + 1):
        dataPointsLabel = self.sample[self.labels == i][0::10]
        traces.append(go.Scatter3d(
            x = dataPointsLabel[:, 1],
            y = dataPointsLabel[:, 2],
            z = dataPointsLabel[:, 3],
            mode = &#39;markers&#39;,
            marker = dict(
                size = 2,
                opacity = 0.8,
                colorscale = &#39;Cividis&#39;
            )
        ))

    if noise == True:
        # Noise points
        dataPointsLabel = self.sample[self.labels == -1][0::10]
        traces.append(go.Scatter3d(
            x = dataPointsLabel[:, 1],
            y = dataPointsLabel[:, 2],
            z = dataPointsLabel[:, 3],
            mode = &#39;markers&#39;,
            marker = dict(
                size = 1,
                opacity = 0.4,
                color = &#39;black&#39;
            )
        ))

    return traces</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.plotCentres"><code class="name flex">
<span>def <span class="ident">plotCentres</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentres(self, ax):

    centres = self.getCentres()
    if len(centres) &gt; 0:
        ax.scatter(centres[:, 1], centres[:, 2], centres[:, 3], c = &#39;r&#39;, marker = &#39;D&#39;, s = 1)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.plotCentresAltAxes"><code class="name flex">
<span>def <span class="ident">plotCentresAltAxes</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentresAltAxes(self, ax):

    centres = self.getCentres()
    if len(centres) &gt; 0:
        ax.scatter(centres[:, 3], centres[:, 1], centres[:, 2], c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.plotSampleLabels"><code class="name flex">
<span>def <span class="ident">plotSampleLabels</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotSampleLabels(self, ax):

    for i in range(0, self.maxLabel + 1):
        dataPointsLabel = self.sample[self.labels == i]
        ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], alpha = 0.6, marker = &#39;1&#39;, s = 1)

    # Plot noise
    dataPointsLabel = self.sample[self.labels == -1]
    ax.scatter(dataPointsLabel[:, 1], dataPointsLabel[:, 2], dataPointsLabel[:, 3], c = &#39;k&#39;, alpha = 0.1, marker = &#39;.&#39;, s = 1)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.ClustererBase.plotSampleLabelsAltAxes"><code class="name flex">
<span>def <span class="ident">plotSampleLabelsAltAxes</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotSampleLabelsAltAxes(self, ax):

    for i in range(0, self.maxLabel + 1):
        dataPointsLabel = self.sample[self.labels == i]
        ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], alpha = 0.6, marker = &#39;1&#39;, s = 1)

    # Plot noise
    dataPointsLabel = self.sample[self.labels == -1]
    ax.scatter(dataPointsLabel[:, 3], dataPointsLabel[:, 1], dataPointsLabel[:, 2], c = &#39;k&#39;, alpha = 0.01, marker = &#39;.&#39;, s = 1)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.Cutpoints"><code class="flex name class">
<span>class <span class="ident">Cutpoints</span></span>
</code></dt>
<dd>
<section class="desc"><p>A class for generic PEPT data iteration, manipulation and visualisation.</p>
<p>This class is used to encapsulate points. Unlike <code>LineData</code>, it does not have
any restriction on the maximum number of columns it can store. It can yield
samples of the <code>point_data</code> of an adaptive <code>sample_size</code> and <code>overlap</code>,
without requiring additional storage.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>point_data</code></strong> :&ensp;(<code>N</code>, <code>M</code>) <code>numpy.ndarray</code></dt>
<dd>An (N, M &gt;= 4) numpy array that stores points (or any generic 2D set of
data). It expects that the first column is time, followed by cartesian
(3D) coordinates of points <strong>in mm</strong>, followed by any extra information
the user needs. A row is then [time, x, y, z, etc].</dd>
<dt><strong><code>sample_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>An <code>int`` that defines the number of points that should be
returned when iterating over</code>point_data<code>. A</code>sample_size` of 0
yields all the data as one single sample. (Default is 200)</dd>
<dt><strong><code>overlap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>An <code>int</code> that defines the overlap between two consecutive
samples that are returned when iterating over <code>point_data</code>.
An overlap of 0 means consecutive samples, while an overlap
of (<code>sample_size</code> - 1) means incrementing the samples by one.
A negative overlap means skipping values between samples. An
error is raised if <code>overlap</code> is larger than or equal to
<code>sample_size</code>. (Default is 0)</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>An option that enables printing the time taken for the
initialisation of an instance of the class. Useful when
reading large files (10gb files for PEPT data is not unheard
of). (Default is True)</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>point_data</code></strong> :&ensp;(<code>N</code>, <code>M</code>) <code>numpy.ndarray</code></dt>
<dd>An (N, M &gt;= 4) numpy array that stores the points as time, followed by
cartesian (3D) coordinates of the point <strong>in mm</strong>, followed by any extra
information. Each row is then <code>[time, x, y, z, etc]</code>.</dd>
<dt><strong><code>sample_size</code></strong> :&ensp;<code>int</code></dt>
<dd>An <code>int</code> that defines the number of lines that should be
returned when iterating over <code>point_data</code>. (Default is 200)</dd>
<dt><strong><code>overlap</code></strong> :&ensp;<code>int</code></dt>
<dd>An <code>int</code> that defines the overlap between two consecutive
samples that are returned when iterating over <code>point_data</code>.
An overlap of 0 means consecutive samples, while an overlap
of (<code>sample_size</code> - 1) means incrementing the samples by one.
A negative overlap means skipping values between samples. It
is required to be smaller than <code>sample_size</code>. (Default is 0)</dd>
<dt><strong><code>number_of_points</code></strong> :&ensp;<code>int</code></dt>
<dd>An <code>int</code> that corresponds to len(<code>point_data</code>), or the number of
points stored by <code>point_data</code>.</dd>
<dt><strong><code>number_of_samples</code></strong> :&ensp;<code>int</code></dt>
<dd>An <code>int</code> that corresponds to the number of samples that can be
accessed from the class, taking the <code>overlap</code> into consideration.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If <code>overlap</code> &gt;= <code>sample_size</code>. Overlap is required to be smaller
than <code>sample_size</code>, unless <code>sample_size</code> is 0. Note that it can
also be negative.</dd>
<dt><code>ValueError</code></dt>
<dd>If <code>line_data</code> does not have (N, M) shape, where M &gt;= 4.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>The class saves <code>point_data</code> as a <strong>contiguous</strong> numpy array for
efficient access in C extensions.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class Cutpoints(pept.PointData):

    def __init__(self):

        # Call pept.PointData constructor with dummy data
        super().__init__([[0., 0., 0., 0.]],
                         sample_size = 0,
                         overlap = 0,
                         verbose = False)


    @staticmethod
    def get_cutoffs(sample):

        # Check sample has shape (N, 7)
        if sample.ndim != 2 or sample.shape[1] != 7:
            raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

        # Compute cutoffs for cutpoints as the (min, max) values of the lines
        # Minimum value of the two points that define a line
        min_x = min(sample[:, 1].min(),
                    sample[:, 4].min())
        # Maximum value of the two points that define a line
        max_x = max(sample[:, 1].max(),
                    sample[:, 4].max())

        # Minimum value of the two points that define a line
        min_y = min(sample[:, 2].min(),
                    sample[:, 5].min())
        # Maximum value of the two points that define a line
        max_y = max(sample[:, 2].max(),
                    sample[:, 5].max())

        # Minimum value of the two points that define a line
        min_z = min(sample[:, 3].min(),
                    sample[:, 6].min())
        # Maximum value of the two points that define a line
        max_z = max(sample[:, 3].max(),
                    sample[:, 6].max())

        cutoffs = np.array([min_x, max_x, min_y, max_y, min_z, max_z])
        return cutoffs


    @staticmethod
    def find_cutpoints_sample(sample, max_distance, cutoffs = None):

        # Check sample has shape (N, 7)
        if sample.ndim != 2 or sample.shape[1] != 7:
            raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

        if cutoffs is None:
            cutoffs = Cutpoints.get_cutoffs(sample)
        else:
            cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
            if cutoffs.ndim != 1 or len(cutoffs) != 6:
                raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

        sample_cutpoints = find_cutpoints_api(sample, max_distance, cutoffs)
        return sample_cutpoints


    def find_cutpoints(self,
                       line_data,
                       max_distance,
                       cutoffs = None,
                       verbose = True):

        if verbose:
            start = time.time()

        # Check line_data is an instance (or a subclass!) of pept.LineData
        if not isinstance(line_data, pept.LineData):
            raise Exception(&#39;[ERROR]: line_data should be an instance of pept.LineData&#39;)

        # If cutoffs were not supplied, compute them
        if cutoffs is None:
            cutoffs = self.get_cutoffs(line_data.line_data)
        # Otherwise make sure they are a C-contiguous numpy array
        else:
            cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
            if cutoffs.ndim != 1 or len(cutoffs) != 6:
                raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

        # Using joblib, collect the cutpoints from every sample in a list
        # of arrays
        cutpoints = Parallel(n_jobs = -1, prefer = &#39;threads&#39;)(delayed(self.find_cutpoints_sample)(sample, max_distance, cutoffs) for sample in tqdm(line_data))

        # cutpoints shape: (n, m, 4), where n is the number of samples, and
        # m is the number of cutpoints in the sample
        cutpoints = np.array(cutpoints)

        number_of_samples = len(cutpoints)
        cutpoints = np.vstack(np.array(cutpoints))
        number_of_cutpoints = len(cutpoints)

        # Average number of cutpoints per sample
        cutpoints_per_sample = int(number_of_cutpoints / number_of_samples)

        super().__init__(cutpoints,
                         sample_size = cutpoints_per_sample,
                         overlap = 0,
                         verbose = False)

        if verbose:
            end = time.time()
            print(&#34;\n\n\nFinding the cutpoints took {} seconds&#34;.format(end - start))

        return self</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pept.data.base.PointData" href="../../data/base.html#pept.data.base.PointData">PointData</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.Cutpoints.find_cutpoints_sample"><code class="name flex">
<span>def <span class="ident">find_cutpoints_sample</span></span>(<span>sample, max_distance, cutoffs=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@staticmethod
def find_cutpoints_sample(sample, max_distance, cutoffs = None):

    # Check sample has shape (N, 7)
    if sample.ndim != 2 or sample.shape[1] != 7:
        raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

    if cutoffs is None:
        cutoffs = Cutpoints.get_cutoffs(sample)
    else:
        cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
        if cutoffs.ndim != 1 or len(cutoffs) != 6:
            raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

    sample_cutpoints = find_cutpoints_api(sample, max_distance, cutoffs)
    return sample_cutpoints</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.Cutpoints.get_cutoffs"><code class="name flex">
<span>def <span class="ident">get_cutoffs</span></span>(<span>sample)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@staticmethod
def get_cutoffs(sample):

    # Check sample has shape (N, 7)
    if sample.ndim != 2 or sample.shape[1] != 7:
        raise ValueError(&#39;\n[ERROR]: sample should have dimensions (N, 7). Received {}\n&#39;.format(sample.shape))

    # Compute cutoffs for cutpoints as the (min, max) values of the lines
    # Minimum value of the two points that define a line
    min_x = min(sample[:, 1].min(),
                sample[:, 4].min())
    # Maximum value of the two points that define a line
    max_x = max(sample[:, 1].max(),
                sample[:, 4].max())

    # Minimum value of the two points that define a line
    min_y = min(sample[:, 2].min(),
                sample[:, 5].min())
    # Maximum value of the two points that define a line
    max_y = max(sample[:, 2].max(),
                sample[:, 5].max())

    # Minimum value of the two points that define a line
    min_z = min(sample[:, 3].min(),
                sample[:, 6].min())
    # Maximum value of the two points that define a line
    max_z = max(sample[:, 3].max(),
                sample[:, 6].max())

    cutoffs = np.array([min_x, max_x, min_y, max_y, min_z, max_z])
    return cutoffs</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.Cutpoints.find_cutpoints"><code class="name flex">
<span>def <span class="ident">find_cutpoints</span></span>(<span>self, line_data, max_distance, cutoffs=None, verbose=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def find_cutpoints(self,
                   line_data,
                   max_distance,
                   cutoffs = None,
                   verbose = True):

    if verbose:
        start = time.time()

    # Check line_data is an instance (or a subclass!) of pept.LineData
    if not isinstance(line_data, pept.LineData):
        raise Exception(&#39;[ERROR]: line_data should be an instance of pept.LineData&#39;)

    # If cutoffs were not supplied, compute them
    if cutoffs is None:
        cutoffs = self.get_cutoffs(line_data.line_data)
    # Otherwise make sure they are a C-contiguous numpy array
    else:
        cutoffs = np.asarray(cutoffs, order = &#39;C&#39;, dtype = float)
        if cutoffs.ndim != 1 or len(cutoffs) != 6:
            raise ValueError(&#39;\n[ERROR]: cutoffs should be a one-dimensional array with values [min_x, max_x, min_y, max_y, min_z, max_z]\n&#39;)

    # Using joblib, collect the cutpoints from every sample in a list
    # of arrays
    cutpoints = Parallel(n_jobs = -1, prefer = &#39;threads&#39;)(delayed(self.find_cutpoints_sample)(sample, max_distance, cutoffs) for sample in tqdm(line_data))

    # cutpoints shape: (n, m, 4), where n is the number of samples, and
    # m is the number of cutpoints in the sample
    cutpoints = np.array(cutpoints)

    number_of_samples = len(cutpoints)
    cutpoints = np.vstack(np.array(cutpoints))
    number_of_cutpoints = len(cutpoints)

    # Average number of cutpoints per sample
    cutpoints_per_sample = int(number_of_cutpoints / number_of_samples)

    super().__init__(cutpoints,
                     sample_size = cutpoints_per_sample,
                     overlap = 0,
                     verbose = False)

    if verbose:
        end = time.time()
        print(&#34;\n\n\nFinding the cutpoints took {} seconds&#34;.format(end - start))

    return self</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pept.data.base.PointData" href="../../data/base.html#pept.data.base.PointData">PointData</a></b></code>:
<ul class="hlist">
<li><code><a title="pept.data.base.PointData.all_points_trace" href="../../data/base.html#pept.data.base.PointData.all_points_trace">all_points_trace</a></code></li>
<li><code><a title="pept.data.base.PointData.all_points_trace_colorbar" href="../../data/base.html#pept.data.base.PointData.all_points_trace_colorbar">all_points_trace_colorbar</a></code></li>
<li><code><a title="pept.data.base.PointData.number_of_points" href="../../data/base.html#pept.data.base.PointData.number_of_points">number_of_points</a></code></li>
<li><code><a title="pept.data.base.PointData.number_of_samples" href="../../data/base.html#pept.data.base.PointData.number_of_samples">number_of_samples</a></code></li>
<li><code><a title="pept.data.base.PointData.overlap" href="../../data/base.html#pept.data.base.PointData.overlap">overlap</a></code></li>
<li><code><a title="pept.data.base.PointData.plot_all_points" href="../../data/base.html#pept.data.base.PointData.plot_all_points">plot_all_points</a></code></li>
<li><code><a title="pept.data.base.PointData.plot_all_points_alt_axes" href="../../data/base.html#pept.data.base.PointData.plot_all_points_alt_axes">plot_all_points_alt_axes</a></code></li>
<li><code><a title="pept.data.base.PointData.plot_points_sample_n" href="../../data/base.html#pept.data.base.PointData.plot_points_sample_n">plot_points_sample_n</a></code></li>
<li><code><a title="pept.data.base.PointData.plot_points_sample_n_alt_axes" href="../../data/base.html#pept.data.base.PointData.plot_points_sample_n_alt_axes">plot_points_sample_n_alt_axes</a></code></li>
<li><code><a title="pept.data.base.PointData.point_data" href="../../data/base.html#pept.data.base.PointData.point_data">point_data</a></code></li>
<li><code><a title="pept.data.base.PointData.points_sample_n_trace" href="../../data/base.html#pept.data.base.PointData.points_sample_n_trace">points_sample_n_trace</a></code></li>
<li><code><a title="pept.data.base.PointData.points_sample_n_trace_colorbar" href="../../data/base.html#pept.data.base.PointData.points_sample_n_trace_colorbar">points_sample_n_trace_colorbar</a></code></li>
<li><code><a title="pept.data.base.PointData.sample_n" href="../../data/base.html#pept.data.base.PointData.sample_n">sample_n</a></code></li>
<li><code><a title="pept.data.base.PointData.sample_size" href="../../data/base.html#pept.data.base.PointData.sample_size">sample_size</a></code></li>
<li><code><a title="pept.data.base.PointData.to_csv" href="../../data/base.html#pept.data.base.PointData.to_csv">to_csv</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer"><code class="flex name class">
<span>class <span class="ident">HDBSCANClusterer</span></span>
<span>(</span><span>min_cluster_size=5, min_samples=None, allow_single_cluster=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class HDBSCANClusterer:

    def __init__(self,
                 min_cluster_size = 5,
                 min_samples = None,
                 allow_single_cluster = False):

        if 0 &lt; min_cluster_size &lt; 2:
            print(&#34;\n[WARNING]: min_cluster_size was set to 2, as it was {} &lt; 2\n&#34;.format(min_cluster_size))
            min_cluster_size = 2

        self.clusterer = hdbscan.HDBSCAN(min_cluster_size = min_cluster_size,
                                         min_samples = min_samples,
                                         core_dist_n_jobs = -1,
                                         allow_single_cluster = allow_single_cluster)

        &#39;&#39;&#39;
        # Call pept.PointData constructor with dummy data
        super().__init__([[0., 0., 0., 0.]],
                         sample_size = 0,
                         overlap = 0,
                         verbose = False)
        &#39;&#39;&#39;


    @property
    def min_cluster_size(self):
        return self.clusterer.min_cluster_size


    @min_cluster_size.setter
    def min_cluster_size(self, new_min_cluster_size):
        self.clusterer.min_cluster_size = new_min_cluster_size


    @property
    def min_samples(self):
        return self.clusterer.min_cluster_size


    @min_samples.setter
    def min_samples(self, new_min_samples):
        self.clusterer.min_samples = new_min_samples


    @property
    def allow_single_cluster(self):
        return self.clusterer.allow_single_cluster


    @allow_single_cluster.setter
    def allow_single_cluster(self, option):
        self.clusterer.allow_single_cluster = option


    def fit_sample(self,
                   sample,
                   store_labels = False,
                   noise = False,
                   as_array = False,
                   verbose = False):

        if verbose:
            start = time.time()

        # sample row: [time, x, y, z]
        if sample.ndim != 2 or sample.shape[1] &lt; 4:
            raise ValueError(&#39;\n[ERROR]: sample should have two dimensions (M, N), where N &gt;= 4. Received {}\n&#39;.format(sample.shape))

        # Only cluster based on [x, y, z]
        labels = self.clusterer.fit_predict(sample[:, 1:4])
        max_label = labels.max()

        centres = []
        clustered_cutpoints = []

        # the centre of a cluster is the average of the time, x, y, z columns
        # and the number of points of that cluster
        # centres row: [time, x, y, z, ..etc.., cluster_size]
        centres = []
        for i in range(0, max_label + 1):
            # Average time, x, y, z of cluster of label i
            centres_row = np.mean(sample[labels == i], axis = 0)
            # Append the number of points of label i =&gt; cluster_size
            centres_row = np.append(centres_row, (labels == i).sum())
            centres.append(centres_row)

        centres = np.array(centres)

        if not as_array:
            centres = pept.PointData(centres,
                                     sample_size = 0,
                                     overlap = 0,
                                     verbose = False)

        # Return all cutpoints as a list of numpy arrays for every label
        # where the last column of an array is the label
        if store_labels:
            # Create a list of numpy arrays with rows: [t, x, y, z, ..etc.., label]
            if noise:
                cutpoints = sample[labels == -1]
                cutpoints = np.insert(cutpoints, cutpoints.shape[1], -1, axis = 1)
                clustered_cutpoints.append(cutpoints)

            for i in range(0, max_label + 1):
                cutpoints = sample[labels == i]
                cutpoints = np.insert(cutpoints, cutpoints.shape[1], i, axis = 1)
                clustered_cutpoints.append(cutpoints)

            clustered_cutpoints = np.vstack(np.array(clustered_cutpoints))

            if not as_array:
                clustered_cutpoints = pept.PointData(clustered_cutpoints,
                                                     sample_size = 0,
                                                     overlap = 0,
                                                     verbose = False)

        if verbose:
            end = time.time()
            print(&#34;Fitting one sample took {} seconds&#34;.format(end - start))

        return [centres, clustered_cutpoints]


    def fit_cutpoints(self,
                      cutpoints,
                      store_labels = False,
                      noise = False,
                      verbose = True):

        if verbose:
            start = time.time()

        if not isinstance(cutpoints, pept.PointData):
            raise Exception(&#39;[ERROR]: cutpoints should be an instance of pept.PointData (or any class inheriting from it)&#39;)

        # Fit all samples in `cutpoints` in parallel using joblib
        # Collect all outputs as a list
        data_list = Parallel(n_jobs = -1)(delayed(self.fit_sample)(sample,
                                                store_labels = store_labels,
                                                noise = noise,
                                                as_array = True) for sample in tqdm(cutpoints))

        # Access joblib.Parallel output as list comprehensions
        centres = np.array([row[0] for row in data_list if len(row[0]) != 0])
        if len(centres) != 0:
            centres = pept.PointData(np.vstack(centres),
                                     sample_size = 0,
                                     overlap = 0,
                                     verbose = False)

        if store_labels:
            clustered_cutpoints = np.array([row[1] for row in data_list if len(row[1]) != 0])
            clustered_cutpoints = pept.PointData(np.vstack(np.array(clustered_cutpoints)),
                                                 sample_size = 0,
                                                 overlap = 0,
                                                 verbose = False)

        if verbose:
            end = time.time()
            print(&#34;Fitting cutpoints took {} seconds&#34;.format(end - start))

        if store_labels:
            return [centres, clustered_cutpoints]
        else:
            return [centres, []]




    def fitSampleParallel(self, sample, saveLabels = False, saveNoise = False):
        # Function that will be parallelised
        # Needs to return a list of the needed outputs
        self.fitSample(sample)
        centres = self.getCentres()

        if saveLabels:
            sampleLabelsTraces = self.getSampleLabelsTraces(noise = saveNoise)
        else:
            sampleLabelsTraces = []

        return [centres, sampleLabelsTraces]


    def clusterIterable(self,
                        samples,
                        saveLabels = False,
                        saveNoise = False):

        # Call joblib Parallel subroutine for every sample needed
        # Collects returned data as a list of outputs
        dataList = Parallel(n_jobs = -1)(delayed(self.fitSampleParallel)(sample, saveLabels, saveNoise) for sample in tqdm(samples))

        # Access the output from the parallelised function as list comprehensions
        # centres row: [time, x, y, z, meanMidpointsClusterSize]
        self.centres = np.array([dataRow[0] for dataRow in dataList if len(dataRow[0]) != 0])
        if len(self.centres) != 0:
            self.centres = np.vstack(self.centres)

        # Collect all the lists of clustered midpoints traces and flatten them
        # Plot the midpoints only if plotMidpoints == True
        if saveLabels:
            self.labelsTraces = [dataRow[1] for dataRow in dataList]
            self.labelsTraces = [elem for sublist in self.labelsTraces for elem in sublist]

            return [self.centres, self.labelsTraces]
        else:
            return [self.centres, []]</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.allow_single_cluster"><code class="name">var <span class="ident">allow_single_cluster</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@property
def allow_single_cluster(self):
    return self.clusterer.allow_single_cluster</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.clusterer"><code class="name">var <span class="ident">clusterer</span></code></dt>
<dd>
<section class="desc"><h1 id="call-peptpointdata-constructor-with-dummy-data">Call pept.PointData constructor with dummy data</h1>
<p>super().<strong>init</strong>([[0., 0., 0., 0.]],
sample_size = 0,
overlap = 0,
verbose = False)</p></section>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.min_cluster_size"><code class="name">var <span class="ident">min_cluster_size</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@property
def min_cluster_size(self):
    return self.clusterer.min_cluster_size</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.min_samples"><code class="name">var <span class="ident">min_samples</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@property
def min_samples(self):
    return self.clusterer.min_cluster_size</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.clusterIterable"><code class="name flex">
<span>def <span class="ident">clusterIterable</span></span>(<span>self, samples, saveLabels=False, saveNoise=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def clusterIterable(self,
                    samples,
                    saveLabels = False,
                    saveNoise = False):

    # Call joblib Parallel subroutine for every sample needed
    # Collects returned data as a list of outputs
    dataList = Parallel(n_jobs = -1)(delayed(self.fitSampleParallel)(sample, saveLabels, saveNoise) for sample in tqdm(samples))

    # Access the output from the parallelised function as list comprehensions
    # centres row: [time, x, y, z, meanMidpointsClusterSize]
    self.centres = np.array([dataRow[0] for dataRow in dataList if len(dataRow[0]) != 0])
    if len(self.centres) != 0:
        self.centres = np.vstack(self.centres)

    # Collect all the lists of clustered midpoints traces and flatten them
    # Plot the midpoints only if plotMidpoints == True
    if saveLabels:
        self.labelsTraces = [dataRow[1] for dataRow in dataList]
        self.labelsTraces = [elem for sublist in self.labelsTraces for elem in sublist]

        return [self.centres, self.labelsTraces]
    else:
        return [self.centres, []]</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.fitSampleParallel"><code class="name flex">
<span>def <span class="ident">fitSampleParallel</span></span>(<span>self, sample, saveLabels=False, saveNoise=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def fitSampleParallel(self, sample, saveLabels = False, saveNoise = False):
    # Function that will be parallelised
    # Needs to return a list of the needed outputs
    self.fitSample(sample)
    centres = self.getCentres()

    if saveLabels:
        sampleLabelsTraces = self.getSampleLabelsTraces(noise = saveNoise)
    else:
        sampleLabelsTraces = []

    return [centres, sampleLabelsTraces]</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.fit_cutpoints"><code class="name flex">
<span>def <span class="ident">fit_cutpoints</span></span>(<span>self, cutpoints, store_labels=False, noise=False, verbose=True)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def fit_cutpoints(self,
                  cutpoints,
                  store_labels = False,
                  noise = False,
                  verbose = True):

    if verbose:
        start = time.time()

    if not isinstance(cutpoints, pept.PointData):
        raise Exception(&#39;[ERROR]: cutpoints should be an instance of pept.PointData (or any class inheriting from it)&#39;)

    # Fit all samples in `cutpoints` in parallel using joblib
    # Collect all outputs as a list
    data_list = Parallel(n_jobs = -1)(delayed(self.fit_sample)(sample,
                                            store_labels = store_labels,
                                            noise = noise,
                                            as_array = True) for sample in tqdm(cutpoints))

    # Access joblib.Parallel output as list comprehensions
    centres = np.array([row[0] for row in data_list if len(row[0]) != 0])
    if len(centres) != 0:
        centres = pept.PointData(np.vstack(centres),
                                 sample_size = 0,
                                 overlap = 0,
                                 verbose = False)

    if store_labels:
        clustered_cutpoints = np.array([row[1] for row in data_list if len(row[1]) != 0])
        clustered_cutpoints = pept.PointData(np.vstack(np.array(clustered_cutpoints)),
                                             sample_size = 0,
                                             overlap = 0,
                                             verbose = False)

    if verbose:
        end = time.time()
        print(&#34;Fitting cutpoints took {} seconds&#34;.format(end - start))

    if store_labels:
        return [centres, clustered_cutpoints]
    else:
        return [centres, []]</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANClusterer.fit_sample"><code class="name flex">
<span>def <span class="ident">fit_sample</span></span>(<span>self, sample, store_labels=False, noise=False, as_array=False, verbose=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def fit_sample(self,
               sample,
               store_labels = False,
               noise = False,
               as_array = False,
               verbose = False):

    if verbose:
        start = time.time()

    # sample row: [time, x, y, z]
    if sample.ndim != 2 or sample.shape[1] &lt; 4:
        raise ValueError(&#39;\n[ERROR]: sample should have two dimensions (M, N), where N &gt;= 4. Received {}\n&#39;.format(sample.shape))

    # Only cluster based on [x, y, z]
    labels = self.clusterer.fit_predict(sample[:, 1:4])
    max_label = labels.max()

    centres = []
    clustered_cutpoints = []

    # the centre of a cluster is the average of the time, x, y, z columns
    # and the number of points of that cluster
    # centres row: [time, x, y, z, ..etc.., cluster_size]
    centres = []
    for i in range(0, max_label + 1):
        # Average time, x, y, z of cluster of label i
        centres_row = np.mean(sample[labels == i], axis = 0)
        # Append the number of points of label i =&gt; cluster_size
        centres_row = np.append(centres_row, (labels == i).sum())
        centres.append(centres_row)

    centres = np.array(centres)

    if not as_array:
        centres = pept.PointData(centres,
                                 sample_size = 0,
                                 overlap = 0,
                                 verbose = False)

    # Return all cutpoints as a list of numpy arrays for every label
    # where the last column of an array is the label
    if store_labels:
        # Create a list of numpy arrays with rows: [t, x, y, z, ..etc.., label]
        if noise:
            cutpoints = sample[labels == -1]
            cutpoints = np.insert(cutpoints, cutpoints.shape[1], -1, axis = 1)
            clustered_cutpoints.append(cutpoints)

        for i in range(0, max_label + 1):
            cutpoints = sample[labels == i]
            cutpoints = np.insert(cutpoints, cutpoints.shape[1], i, axis = 1)
            clustered_cutpoints.append(cutpoints)

        clustered_cutpoints = np.vstack(np.array(clustered_cutpoints))

        if not as_array:
            clustered_cutpoints = pept.PointData(clustered_cutpoints,
                                                 sample_size = 0,
                                                 overlap = 0,
                                                 verbose = False)

    if verbose:
        end = time.time()
        print(&#34;Fitting one sample took {} seconds&#34;.format(end - start))

    return [centres, clustered_cutpoints]</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANclustererAuto"><code class="flex name class">
<span>class <span class="ident">HDBSCANclustererAuto</span></span>
<span>(</span><span>sampleSize, k=[0.001, 0.8], nIter=5)</span>
</code></dt>
<dd>
<section class="desc"><p>Automatically vary the harshness of an HDBSCAN clusterer until
a particle has been found</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class HDBSCANclustererAuto(ClustererBase):
    &#39;&#39;&#39;
    Automatically vary the harshness of an HDBSCAN clusterer until
    a particle has been found
    &#39;&#39;&#39;

    def __init__(self, sampleSize, k = [0.001, 0.8], nIter = 5):
        # sampleSize is the average number of points per particle

        # k is a correction factor ranging from 0 to 1, having the
        # physical meaning of the minimum ratio of points that
        # need to be part of the cluster.
        #   eg. k = 1 means all points need to be close together =&gt; harsher
        #       k = 0.2 means 20% of points need to be close =&gt; more lenient
        self.sampleSize = sampleSize
        self.k = k
        self.nIter = nIter

        if self.sampleSize &lt;= 0:
            raise Exception(&#39;[ERROR]: sampleSize needs to be a positive integer&#39;)

        # Create a list of clusterers with min_cluster_size ranging from min to max, with
        # nIter maximum iterations to find a centre

        self.autoClusterer = []

        # lenient because smaller minimum cluster size =&gt; more points into cluster
        min_min_cluster_size = k[0] * self.sampleSize #self.sampleSize / 30#10

        # harsh
        max_min_cluster_size = k[1] * self.sampleSize #self.sampleSize / 20#5

        # from harsh to lenient
        sizes = np.linspace(max_min_cluster_size, min_min_cluster_size, self.nIter)

        for min_cluster_size in sizes:
            min_cluster_size = int(min_cluster_size)
            if min_cluster_size &lt; 2:
                min_cluster_size = 2
            self.autoClusterer.append(hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,
                                                      core_dist_n_jobs = -1))


    def changeParameters(self, sampleSize = 0, nIter = 5):
        if sampleSize != 0:
            if self.sampleSize &lt;= 0 or type(sampleSize) != int:
                raise Exception(&#39;[ERROR]: sampleSize needs to be a positive integer&#39;)
            else:
                self.sampleSize = sampleSize

        self.nIter = nIter

        if self.sampleSize != 0:
            # Create a list of clusterers with min_cluster_size ranging from min to max, with
            # nIter maximum iterations to find a centre

            self.autoClusterer = []

            # lenient because smaller minimum cluster size =&gt; more points into cluster
            min_min_cluster_size = self.sampleSize / 10

            # harsh
            max_min_cluster_size = self.sampleSize / 5

            # from harsh to lenient
            sizes = np.linspace(max_min_cluster_size, min_min_cluster_size, self.nIter)

            for min_cluster_size in sizes:
                self.autoClusterer.append(hdbscan.HDBSCAN(min_cluster_size=int(min_cluster_size)))


    def fitSample(self, sample):
        #start = time.time()

        # sample row: [time, x, y, z]
        self.sample = sample

        for clusterer in self.autoClusterer:
            # Only cluster based on [x, y, z]
            clusterer.fit(self.sample[:, 1:4])
            self.labels = clusterer.labels_
            self.maxLabel = self.labels.max()

            # Stop when a particle was found
            if self.maxLabel &gt;= 0:
                break</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pept.tracking.peptml.peptml.ClustererBase" href="#pept.tracking.peptml.peptml.ClustererBase">ClustererBase</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.HDBSCANclustererAuto.changeParameters"><code class="name flex">
<span>def <span class="ident">changeParameters</span></span>(<span>self, sampleSize=0, nIter=5)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def changeParameters(self, sampleSize = 0, nIter = 5):
    if sampleSize != 0:
        if self.sampleSize &lt;= 0 or type(sampleSize) != int:
            raise Exception(&#39;[ERROR]: sampleSize needs to be a positive integer&#39;)
        else:
            self.sampleSize = sampleSize

    self.nIter = nIter

    if self.sampleSize != 0:
        # Create a list of clusterers with min_cluster_size ranging from min to max, with
        # nIter maximum iterations to find a centre

        self.autoClusterer = []

        # lenient because smaller minimum cluster size =&gt; more points into cluster
        min_min_cluster_size = self.sampleSize / 10

        # harsh
        max_min_cluster_size = self.sampleSize / 5

        # from harsh to lenient
        sizes = np.linspace(max_min_cluster_size, min_min_cluster_size, self.nIter)

        for min_cluster_size in sizes:
            self.autoClusterer.append(hdbscan.HDBSCAN(min_cluster_size=int(min_cluster_size)))</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANclustererAuto.fitSample"><code class="name flex">
<span>def <span class="ident">fitSample</span></span>(<span>self, sample)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def fitSample(self, sample):
    #start = time.time()

    # sample row: [time, x, y, z]
    self.sample = sample

    for clusterer in self.autoClusterer:
        # Only cluster based on [x, y, z]
        clusterer.fit(self.sample[:, 1:4])
        self.labels = clusterer.labels_
        self.maxLabel = self.labels.max()

        # Stop when a particle was found
        if self.maxLabel &gt;= 0:
            break</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer"><code class="flex name class">
<span>class <span class="ident">HDBSCANtwoPassClusterer</span></span>
<span>(</span><span>clusterer, clusterer2, samplesMidpoints, centresSampleSize, centresOverlap=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Helper class which implements a second pass of clustering
over the centres found by 'clusterer'</p>
<p>Two-pass clustering helps with spatial resolution and
determining the trajectory of a moving particle</p>
<pre><code>clusterer: a clusterer which has the method fitSample(sample) that will
    fit samples of midpoints (first-pass clustering)

clusterer2: a clusterer which has the method fitSample(sample) that will
    fit samples of centres (second-pass clustering)

samplesMidpoints: an array of samples of midpoints.
    samplesMidpoints.shape: (numberOfSamples, numberOfMidpointsPerSample, 4)
    (can alternatively send a Midpoints instance which can be iterated over)

centresSampleSize: number of centres to send per sample  to the second reclustering
</code></pre></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class HDBSCANtwoPassClusterer:
    &#39;&#39;&#39;
    Helper class which implements a second pass of clustering
    over the centres found by &#39;clusterer&#39;

    Two-pass clustering helps with spatial resolution and
    determining the trajectory of a moving particle

        clusterer: a clusterer which has the method fitSample(sample) that will
            fit samples of midpoints (first-pass clustering)

        clusterer2: a clusterer which has the method fitSample(sample) that will
            fit samples of centres (second-pass clustering)

        samplesMidpoints: an array of samples of midpoints.
            samplesMidpoints.shape: (numberOfSamples, numberOfMidpointsPerSample, 4)
            (can alternatively send a Midpoints instance which can be iterated over)

        centresSampleSize: number of centres to send per sample  to the second reclustering
    &#39;&#39;&#39;

    def __init__(self, clusterer, clusterer2, samplesMidpoints, centresSampleSize, centresOverlap=0):
        # clusterer is an instance which has the method .fitSample(sample)
        # samplesMidpoints is an array of samples of midpoints
        # samplesMidpoints.shape: (numberOfSamples, numberOfMidpointsPerSample, 4)
        # (can alternatively send a Midpoints instance which can be iterated over)

        self.clusterer = clusterer
        self.clusterer2 = clusterer2
        self.samplesMidpoints = samplesMidpoints
        self.centresSampleSize = centresSampleSize
        self.centresOverlap = centresOverlap
        self.centres = []
        self.centres2 = []


    def fit(self):

        start = time.time()
        # First pass of clustering for midpoints
        for sample in self.samplesMidpoints:
            self.clusterer.fitSample(sample)
            newCentres = self.clusterer.getCentres()
            self.centres.extend(newCentres)

        end = time.time()
        print(&#39;First pass of clustering took {} s&#39;.format(end - start))

        # centres row: [time, x, y, z, clusterSize]
        self.centres = np.array(self.centres)

        self.samplesCentres = ClusterCentres(self.centres, self.centresSampleSize, self.centresOverlap)

        print(&#39;Total number of samples of centres: {}&#39;.format(self.samplesCentres.getNumberOfSamples()))

        start = time.time()
        # Second pass of clustering for centres
        for sample in self.samplesCentres:
            self.clusterer2.fitSample(sample)
            newCentres = self.clusterer2.getCentres()
            self.centres2.extend(newCentres)

        end = time.time()
        print(&#39;Second pass of clustering took {} s&#39;.format(end - start))

        # centres2 row: [time, x, y, z, meanCentresClusterSize, clusterSize]
        self.centres2 = np.array(self.centres2)


    def getCentres(self):
        return self.centres


    def getCentres2(self):
        return self.centres2


    def plotCentres(self, ax):

        if len(self.centres) &gt; 0:
            ax.scatter(self.centres[:, 1], self.centres[:, 2], self.centres[:, 3],
                    c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentresAltAxes(self, ax):

        if len(self.centres) &gt; 0:
            ax.scatter(self.centres[:, 3], self.centres[:, 1], self.centres[:, 2],
                    c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentres2(self, ax):

        if len(self.centres2) &gt; 0:
            ax.scatter(self.centres2[:, 1], self.centres2[:, 2], self.centres2[:, 3],
                    c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)


    def plotCentres2AltAxes(self, ax):

        if len(self.centres2) &gt; 0:
            ax.scatter(self.centres2[:, 3], self.centres2[:, 1], self.centres2[:, 2],
                    c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def fit(self):

    start = time.time()
    # First pass of clustering for midpoints
    for sample in self.samplesMidpoints:
        self.clusterer.fitSample(sample)
        newCentres = self.clusterer.getCentres()
        self.centres.extend(newCentres)

    end = time.time()
    print(&#39;First pass of clustering took {} s&#39;.format(end - start))

    # centres row: [time, x, y, z, clusterSize]
    self.centres = np.array(self.centres)

    self.samplesCentres = ClusterCentres(self.centres, self.centresSampleSize, self.centresOverlap)

    print(&#39;Total number of samples of centres: {}&#39;.format(self.samplesCentres.getNumberOfSamples()))

    start = time.time()
    # Second pass of clustering for centres
    for sample in self.samplesCentres:
        self.clusterer2.fitSample(sample)
        newCentres = self.clusterer2.getCentres()
        self.centres2.extend(newCentres)

    end = time.time()
    print(&#39;Second pass of clustering took {} s&#39;.format(end - start))

    # centres2 row: [time, x, y, z, meanCentresClusterSize, clusterSize]
    self.centres2 = np.array(self.centres2)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres"><code class="name flex">
<span>def <span class="ident">getCentres</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getCentres(self):
    return self.centres</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres2"><code class="name flex">
<span>def <span class="ident">getCentres2</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getCentres2(self):
    return self.centres2</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres"><code class="name flex">
<span>def <span class="ident">plotCentres</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentres(self, ax):

    if len(self.centres) &gt; 0:
        ax.scatter(self.centres[:, 1], self.centres[:, 2], self.centres[:, 3],
                c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2"><code class="name flex">
<span>def <span class="ident">plotCentres2</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentres2(self, ax):

    if len(self.centres2) &gt; 0:
        ax.scatter(self.centres2[:, 1], self.centres2[:, 2], self.centres2[:, 3],
                c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2AltAxes"><code class="name flex">
<span>def <span class="ident">plotCentres2AltAxes</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentres2AltAxes(self, ax):

    if len(self.centres2) &gt; 0:
        ax.scatter(self.centres2[:, 3], self.centres2[:, 1], self.centres2[:, 2],
                c = &#39;b&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentresAltAxes"><code class="name flex">
<span>def <span class="ident">plotCentresAltAxes</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotCentresAltAxes(self, ax):

    if len(self.centres) &gt; 0:
        ax.scatter(self.centres[:, 3], self.centres[:, 1], self.centres[:, 2],
                c = &#39;r&#39;, marker = &#39;D&#39;, s = 5)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher"><code class="flex name class">
<span>class <span class="ident">PlotlyGrapher</span></span>
<span>(</span><span>rows=1, cols=1, xlim=[0, 500], ylim=[0, 500], zlim=[0, 712], subplot_titles=['
'])</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class PlotlyGrapher:
    # Helper class that automatically generates Plotly graphs
    # for the PEPT data

    def __init__(self, rows=1, cols=1, xlim = [0, 500],
                 ylim = [0, 500], zlim = [0, 712], subplot_titles = [&#39;  &#39;]):
        self.rows = rows
        self.cols = cols

        self.xlim = xlim
        self.ylim = ylim
        self.zlim = zlim

        self.subplot_titles = subplot_titles
        self.subplot_titles.extend([&#39;  &#39;] * (rows * cols - len(subplot_titles)))


    def createFigure(self):
        # Create subplots and set limits

        specs = [[{&#34;type&#34;: &#34;scatter3d&#34;}] * self.cols] * self.rows

        self.fig = make_subplots(rows = self.rows, cols = self.cols,
                    specs = specs, subplot_titles = self.subplot_titles,
                    horizontal_spacing = 0.005, vertical_spacing = 0.05)

        self.fig[&#39;layout&#39;].update(margin = dict(l=0,r=0,b=30,t=30), showlegend = False)

        # For every subplot (scene), set axes&#39; ratios and limits
        # Also set the y axis to point upwards
        # Plotly naming convention of scenes: &#39;scene&#39;, &#39;scene2&#39;, etc.
        for i in range(self.rows):
            for j in range(self.cols):
                if i == j == 0:
                    scene = &#39;scene&#39;
                else:
                    scene = &#39;scene{}&#39;.format(i * self.cols + j + 1)

                # Justify subplot title on the left
                self.fig.layout.annotations[i * self.cols + j].update(x = (j + 0.08) / self.cols)
                self.fig[&#39;layout&#39;][scene].update(aspectmode = &#39;manual&#39;,
                                                 aspectratio = {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1},
                                                 camera = {&#39;up&#39;: {&#39;x&#39;: 0, &#39;y&#39;: 1, &#39;z&#39;:0},
                                                           &#39;eye&#39;: {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1}},
                                                 xaxis = {&#39;range&#39;: self.xlim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;x&lt;/i&gt; (mm)&#34;}},
                                                 yaxis = {&#39;range&#39;: self.ylim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;y&lt;/i&gt; (mm)&#34;}},
                                                 zaxis = {&#39;range&#39;: self.zlim,
                                                          &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;z&lt;/i&gt; (mm)&#34;}}
                                                 )

        return self.fig


    def getFigure(self):
        return self.fig


    def addDataAsTrace(self, data, row, col, size = 2, color = None):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            trace = go.Scatter3d(
                x = data[:, 1],
                y = data[:, 2],
                z = data[:, 3],
                mode = &#39;markers&#39;,
                marker = dict(
                    size = size,
                    color = color,
                    opacity = 0.8
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addDataAsTraceColorbar(self, data, row, col, titleColorbar = None, size = 3):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            if titleColorbar != None:
                colorbar=dict(title=titleColorbar)
            else:
                colorbar = dict()

            trace = go.Scatter3d(
                x=data[:, 1],
                y=data[:, 2],
                z=data[:, 3],
                mode=&#39;markers&#39;,
                marker=dict(
                    size=size,
                    color=data[:, -1],   # set color to sample size
                    colorscale=&#39;Magma&#39;,     # choose a colorscale
                    colorbar=colorbar,
                    opacity=0.8
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addDataAsTraceLine(self, data, row, col):
        # Expected data row: [time, x, y, z, ...]
        if len(data) != 0:
            trace = go.Scatter3d(
                x=data[:, 1],
                y=data[:, 2],
                z=data[:, 3],
                mode=&#39;lines&#39;,
                line=dict(
                    width=4,
                )
            )

            self.fig.add_trace(trace, row = row, col = col)


    def addTrace(self, trace, row, col):
        # Add precomputed trace
        # Can accept HDBSCANclusterer.getCentresTrace() output
        if len(trace) != 0:
            self.fig.add_traces(trace, rows=row, cols=col)


    def addTraces(self, traces, row, col):
        # Add precomputed traces
        # Can accept HDBSCANclusterer.getSampleLabelsTraces() output
        if len(traces) != 0:
            self.fig.add_traces(traces, rows=[row]*len(traces), cols=[col]*len(traces))


    def showFigure(self):
        self.fig.show()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTrace"><code class="name flex">
<span>def <span class="ident">addDataAsTrace</span></span>(<span>self, data, row, col, size=2, color=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def addDataAsTrace(self, data, row, col, size = 2, color = None):
    # Expected data row: [time, x, y, z, ...]
    if len(data) != 0:
        trace = go.Scatter3d(
            x = data[:, 1],
            y = data[:, 2],
            z = data[:, 3],
            mode = &#39;markers&#39;,
            marker = dict(
                size = size,
                color = color,
                opacity = 0.8
            )
        )

        self.fig.add_trace(trace, row = row, col = col)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceColorbar"><code class="name flex">
<span>def <span class="ident">addDataAsTraceColorbar</span></span>(<span>self, data, row, col, titleColorbar=None, size=3)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def addDataAsTraceColorbar(self, data, row, col, titleColorbar = None, size = 3):
    # Expected data row: [time, x, y, z, ...]
    if len(data) != 0:
        if titleColorbar != None:
            colorbar=dict(title=titleColorbar)
        else:
            colorbar = dict()

        trace = go.Scatter3d(
            x=data[:, 1],
            y=data[:, 2],
            z=data[:, 3],
            mode=&#39;markers&#39;,
            marker=dict(
                size=size,
                color=data[:, -1],   # set color to sample size
                colorscale=&#39;Magma&#39;,     # choose a colorscale
                colorbar=colorbar,
                opacity=0.8
            )
        )

        self.fig.add_trace(trace, row = row, col = col)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceLine"><code class="name flex">
<span>def <span class="ident">addDataAsTraceLine</span></span>(<span>self, data, row, col)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def addDataAsTraceLine(self, data, row, col):
    # Expected data row: [time, x, y, z, ...]
    if len(data) != 0:
        trace = go.Scatter3d(
            x=data[:, 1],
            y=data[:, 2],
            z=data[:, 3],
            mode=&#39;lines&#39;,
            line=dict(
                width=4,
            )
        )

        self.fig.add_trace(trace, row = row, col = col)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.addTrace"><code class="name flex">
<span>def <span class="ident">addTrace</span></span>(<span>self, trace, row, col)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def addTrace(self, trace, row, col):
    # Add precomputed trace
    # Can accept HDBSCANclusterer.getCentresTrace() output
    if len(trace) != 0:
        self.fig.add_traces(trace, rows=row, cols=col)</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.addTraces"><code class="name flex">
<span>def <span class="ident">addTraces</span></span>(<span>self, traces, row, col)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def addTraces(self, traces, row, col):
    # Add precomputed traces
    # Can accept HDBSCANclusterer.getSampleLabelsTraces() output
    if len(traces) != 0:
        self.fig.add_traces(traces, rows=[row]*len(traces), cols=[col]*len(traces))</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.createFigure"><code class="name flex">
<span>def <span class="ident">createFigure</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def createFigure(self):
    # Create subplots and set limits

    specs = [[{&#34;type&#34;: &#34;scatter3d&#34;}] * self.cols] * self.rows

    self.fig = make_subplots(rows = self.rows, cols = self.cols,
                specs = specs, subplot_titles = self.subplot_titles,
                horizontal_spacing = 0.005, vertical_spacing = 0.05)

    self.fig[&#39;layout&#39;].update(margin = dict(l=0,r=0,b=30,t=30), showlegend = False)

    # For every subplot (scene), set axes&#39; ratios and limits
    # Also set the y axis to point upwards
    # Plotly naming convention of scenes: &#39;scene&#39;, &#39;scene2&#39;, etc.
    for i in range(self.rows):
        for j in range(self.cols):
            if i == j == 0:
                scene = &#39;scene&#39;
            else:
                scene = &#39;scene{}&#39;.format(i * self.cols + j + 1)

            # Justify subplot title on the left
            self.fig.layout.annotations[i * self.cols + j].update(x = (j + 0.08) / self.cols)
            self.fig[&#39;layout&#39;][scene].update(aspectmode = &#39;manual&#39;,
                                             aspectratio = {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1},
                                             camera = {&#39;up&#39;: {&#39;x&#39;: 0, &#39;y&#39;: 1, &#39;z&#39;:0},
                                                       &#39;eye&#39;: {&#39;x&#39;: 1, &#39;y&#39;: 1, &#39;z&#39;: 1}},
                                             xaxis = {&#39;range&#39;: self.xlim,
                                                      &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;x&lt;/i&gt; (mm)&#34;}},
                                             yaxis = {&#39;range&#39;: self.ylim,
                                                      &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;y&lt;/i&gt; (mm)&#34;}},
                                             zaxis = {&#39;range&#39;: self.zlim,
                                                      &#39;title&#39;: {&#39;text&#39;: &#34;&lt;i&gt;z&lt;/i&gt; (mm)&#34;}}
                                             )

    return self.fig</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.getFigure"><code class="name flex">
<span>def <span class="ident">getFigure</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getFigure(self):
    return self.fig</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.PlotlyGrapher.showFigure"><code class="name flex">
<span>def <span class="ident">showFigure</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def showFigure(self):
    self.fig.show()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pept.tracking.peptml.peptml.TrajectorySeparation"><code class="flex name class">
<span>class <span class="ident">TrajectorySeparation</span></span>
<span>(</span><span>centres, pointsToCheck=25, maxDistance=20, maxClusterDiff=500)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class TrajectorySeparation:

    def __init__(self, centres, pointsToCheck = 25, maxDistance = 20, maxClusterDiff = 500):
        # centres row: [time, x, y, z, clusterSize]
        # Make sure the trajectory is memory-contiguous for efficient
        # KDTree partitioning
        self.centres = np.ascontiguousarray(centres)
        self.pointsToCheck = pointsToCheck
        self.maxDistance = maxDistance
        self.maxClusterDiff = maxClusterDiff

        # For every point in centres, save a set of the trajectory
        # indices of the trajectories that they are part of
        #   eg. centres[2] is part of trajectories 0 and 1 =&gt;
        #   trajectoryIndices[2] = {0, 1}
        # Initialise a vector of empty sets of size len(centres)
        self.trajectoryIndices = np.array([ set() for i in range(len(self.centres)) ])

        # For every trajectory found, save a list of the indices of
        # the centres that are part of that trajectory
        #   eg. trajectory 1 is comprised of centres 3, 5 and 8 =&gt;
        #   centresIndices[1] = [3, 5, 8]
        self.centresIndices = [[]]

        # Maximum trajectory index
        self.maxIndex = 0


    def findTrajectories(self):

        for i, currentPoint in enumerate(self.centres):

            if i == 0:
                # Add the first point to trajectory 0
                self.trajectoryIndices[0].add(self.maxIndex)
                self.centresIndices[self.maxIndex].append(0)
                self.maxIndex += 1
                continue

            # Search for the closest previous pointsToCheck points
            # within a given maxDistance
            startIndex = i - self.pointsToCheck
            endIndex = i

            if startIndex &lt; 0:
                startIndex = 0

            # Construct a KDTree from the x, y, z (1:4) of the
            # selected points. Get the indices for all the points within
            # maxDistance of the currentPoint
            tree = cKDTree(self.centres[startIndex:endIndex, 1:4])
            closestIndices = tree.query_ball_point(currentPoint[1:4], self.maxDistance, n_jobs=-1)
            closestIndices = np.array(closestIndices) + startIndex

            # If no point was found, it is a new trajectory. Continue
            if len(closestIndices) == 0:
                self.trajectoryIndices[i].add(self.maxIndex)
                self.centresIndices.append([i])
                self.maxIndex += 1
                continue

            # For every close point found, search for all the trajectory indices
            #   - If all trajectory indices sets are equal and of a single value
            #   then currentPoint is part of the same trajectory
            #   - If all trajectory indices sets are equal, but of more values,
            #   then currentPoint diverged from an intersection of trajectories
            #   and is part of a single trajectory =&gt; separate it
            #
            #   - If every pair of trajectory indices sets is not disjoint, then
            #   currentPoint is only one of them
            #   - If there exists a pair of trajectory indices sets that is
            #   disjoint, then currentPoint is part of all of them

            # Select the trajectories of all the points that were found
            # to be the closest
            closestTrajectories = self.trajectoryIndices[closestIndices]
            #print(&#34;closestTrajectories:&#34;)
            #print(closestTrajectories)

            # If all the closest points are part of the same trajectory
            # (just one!), then the currentPoint is part of it too
            if (np.all(closestTrajectories == closestTrajectories[0]) and
                len(closestTrajectories[0]) == 1):

                self.trajectoryIndices[i] = closestTrajectories[0]
                self.centresIndices[ next(iter(closestTrajectories[0])) ].append(i)
                continue

            # Otherwise, check the points based on their cluster size
            else:
                # Create a list of all the trajectories that were found to
                # intersect
                #print(&#39;\nIntersection:&#39;)
                closestTrajIndices = list( set().union(*closestTrajectories) )

                #print(&#34;ClosestTrajIndices:&#34;)
                #print(closestTrajIndices)

                # For each close trajectory, calculate the mean cluster size
                # of the last lastPoints points
                lastPoints = 50

                # Keep track of the mean cluster size that is the closest to
                # the currentPoint&#39;s clusterSize
                currentClusterSize = currentPoint[4]
                #print(&#34;currentClusterSize = {}&#34;.format(currentClusterSize))
                closestTrajIndex = -1
                clusterSizeDiff = self.maxClusterDiff

                for trajIndex in closestTrajIndices:
                    #print(&#34;trajIndex = {}&#34;.format(trajIndex))

                    trajCentres = self.centres[ self.centresIndices[trajIndex] ]
                    #print(&#34;trajCentres:&#34;)
                    #print(trajCentres)
                    meanClusterSize = trajCentres[-lastPoints:][:, 4].mean()
                    #print(&#34;meanClusterSize = {}&#34;.format(meanClusterSize))
                    #print(&#34;clusterSizeDiff = {}&#34;.format(clusterSizeDiff))
                    #print(&#34;abs diff = {}&#34;.format(np.abs( currentClusterSize - meanClusterSize )))
                    if np.abs( currentClusterSize - meanClusterSize ) &lt; clusterSizeDiff:
                        closestTrajIndex = trajIndex
                        clusterSizeDiff = np.abs( currentClusterSize - meanClusterSize )

                if closestTrajIndex == -1:
                    #self.trajectoryIndices[i] = set(closestTrajIndices)
                    #for trajIndex in closestTrajIndices:
                    #    self.centresIndices[trajIndex].append(i)

                    print(&#34;\n**** -1 ****\n&#34;)
                    break
                else:
                    #print(&#34;ClosestTrajIndex found = {}&#34;.format(closestTrajIndex))
                    self.trajectoryIndices[i] = set([closestTrajIndex])
                    self.centresIndices[closestTrajIndex].append(i)




            &#39;&#39;&#39;
            # If the current point is not part of any trajectory, assign it
            # the maxIndex and increment it
            if len(self.trajectoryIndices[i]) == 0:
                self.trajectoryIndices[i].append(self.maxIndex)
                self.maxIndex += 1

            print(self.trajectoryIndices[i])
            print(self.maxIndex)

            # Construct a KDTree from the numberOfPoints in front of
            # the current point
            tree = cKDTree(self.trajectory[(i + 1):(i + self.numberOfPoints + 2)][1:4])

            # For every trajectory that the current point is part of,
            # find the closest points in front of it
            numberOfIntersections = len(self.trajectoryIndices[i])
            dist, nextPointsIndices = tree.query(currentPoint, k=numberOfIntersections, distance_upper_bound=self.maxDistance, n_jobs=-1)

            print(nextPointsIndices)

            # If the current point is part of more trajectories,
            # an intersection happened. Call subroutine to part
            # the trajectories
            if numberOfIntersections &gt; 1:
                for j in range(0, len(self.trajectoryIndices[i])):
                    trajIndex = self.trajectoryIndices[i][j]
                    self.trajectoryIndices[i + 1 + nextPointsIndices[j]].append(trajIndex)

            else:
                self.trajectoryIndices[i + 1 + nextPointsIndices].append(self.trajectoryIndices[i][0])

            print(self.trajectoryIndices)
            &#39;&#39;&#39;


    def getTrajectories(self):

        self.individualTrajectories = []
        for trajCentres in self.centresIndices:
            self.individualTrajectories.append(self.centres[trajCentres])

        self.individualTrajectories = np.array(self.individualTrajectories)
        return self.individualTrajectories

        &#39;&#39;&#39;
        self.individualTrajectories = [ [] for i in range(0, self.maxIndex + 1) ]
        for i in range(0, len(self.trajectoryIndices)):
            for trajIndex in self.trajectoryIndices[i]:
                self.individualTrajectories[trajIndex].append(self.centres[i])

        self.individualTrajectories = np.array(self.individualTrajectories)
        for i in range(len(self.individualTrajectories)):
            if len(self.individualTrajectories[i]) &gt; 0:
                self.individualTrajectories[i] = np.vstack(self.individualTrajectories[i])
        return self.individualTrajectories
        &#39;&#39;&#39;


    def plotTrajectoriesAltAxes(self, ax):
        trajectories = self.getTrajectories()
        for traj in trajectories:
            if len(traj) &gt; 0:
                ax.scatter(traj[:, 3], traj[:, 1], traj[:, 2], marker=&#39;D&#39;, s=10)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pept.tracking.peptml.peptml.TrajectorySeparation.findTrajectories"><code class="name flex">
<span>def <span class="ident">findTrajectories</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def findTrajectories(self):

    for i, currentPoint in enumerate(self.centres):

        if i == 0:
            # Add the first point to trajectory 0
            self.trajectoryIndices[0].add(self.maxIndex)
            self.centresIndices[self.maxIndex].append(0)
            self.maxIndex += 1
            continue

        # Search for the closest previous pointsToCheck points
        # within a given maxDistance
        startIndex = i - self.pointsToCheck
        endIndex = i

        if startIndex &lt; 0:
            startIndex = 0

        # Construct a KDTree from the x, y, z (1:4) of the
        # selected points. Get the indices for all the points within
        # maxDistance of the currentPoint
        tree = cKDTree(self.centres[startIndex:endIndex, 1:4])
        closestIndices = tree.query_ball_point(currentPoint[1:4], self.maxDistance, n_jobs=-1)
        closestIndices = np.array(closestIndices) + startIndex

        # If no point was found, it is a new trajectory. Continue
        if len(closestIndices) == 0:
            self.trajectoryIndices[i].add(self.maxIndex)
            self.centresIndices.append([i])
            self.maxIndex += 1
            continue

        # For every close point found, search for all the trajectory indices
        #   - If all trajectory indices sets are equal and of a single value
        #   then currentPoint is part of the same trajectory
        #   - If all trajectory indices sets are equal, but of more values,
        #   then currentPoint diverged from an intersection of trajectories
        #   and is part of a single trajectory =&gt; separate it
        #
        #   - If every pair of trajectory indices sets is not disjoint, then
        #   currentPoint is only one of them
        #   - If there exists a pair of trajectory indices sets that is
        #   disjoint, then currentPoint is part of all of them

        # Select the trajectories of all the points that were found
        # to be the closest
        closestTrajectories = self.trajectoryIndices[closestIndices]
        #print(&#34;closestTrajectories:&#34;)
        #print(closestTrajectories)

        # If all the closest points are part of the same trajectory
        # (just one!), then the currentPoint is part of it too
        if (np.all(closestTrajectories == closestTrajectories[0]) and
            len(closestTrajectories[0]) == 1):

            self.trajectoryIndices[i] = closestTrajectories[0]
            self.centresIndices[ next(iter(closestTrajectories[0])) ].append(i)
            continue

        # Otherwise, check the points based on their cluster size
        else:
            # Create a list of all the trajectories that were found to
            # intersect
            #print(&#39;\nIntersection:&#39;)
            closestTrajIndices = list( set().union(*closestTrajectories) )

            #print(&#34;ClosestTrajIndices:&#34;)
            #print(closestTrajIndices)

            # For each close trajectory, calculate the mean cluster size
            # of the last lastPoints points
            lastPoints = 50

            # Keep track of the mean cluster size that is the closest to
            # the currentPoint&#39;s clusterSize
            currentClusterSize = currentPoint[4]
            #print(&#34;currentClusterSize = {}&#34;.format(currentClusterSize))
            closestTrajIndex = -1
            clusterSizeDiff = self.maxClusterDiff

            for trajIndex in closestTrajIndices:
                #print(&#34;trajIndex = {}&#34;.format(trajIndex))

                trajCentres = self.centres[ self.centresIndices[trajIndex] ]
                #print(&#34;trajCentres:&#34;)
                #print(trajCentres)
                meanClusterSize = trajCentres[-lastPoints:][:, 4].mean()
                #print(&#34;meanClusterSize = {}&#34;.format(meanClusterSize))
                #print(&#34;clusterSizeDiff = {}&#34;.format(clusterSizeDiff))
                #print(&#34;abs diff = {}&#34;.format(np.abs( currentClusterSize - meanClusterSize )))
                if np.abs( currentClusterSize - meanClusterSize ) &lt; clusterSizeDiff:
                    closestTrajIndex = trajIndex
                    clusterSizeDiff = np.abs( currentClusterSize - meanClusterSize )

            if closestTrajIndex == -1:
                #self.trajectoryIndices[i] = set(closestTrajIndices)
                #for trajIndex in closestTrajIndices:
                #    self.centresIndices[trajIndex].append(i)

                print(&#34;\n**** -1 ****\n&#34;)
                break
            else:
                #print(&#34;ClosestTrajIndex found = {}&#34;.format(closestTrajIndex))
                self.trajectoryIndices[i] = set([closestTrajIndex])
                self.centresIndices[closestTrajIndex].append(i)




        &#39;&#39;&#39;
        # If the current point is not part of any trajectory, assign it
        # the maxIndex and increment it
        if len(self.trajectoryIndices[i]) == 0:
            self.trajectoryIndices[i].append(self.maxIndex)
            self.maxIndex += 1

        print(self.trajectoryIndices[i])
        print(self.maxIndex)

        # Construct a KDTree from the numberOfPoints in front of
        # the current point
        tree = cKDTree(self.trajectory[(i + 1):(i + self.numberOfPoints + 2)][1:4])

        # For every trajectory that the current point is part of,
        # find the closest points in front of it
        numberOfIntersections = len(self.trajectoryIndices[i])
        dist, nextPointsIndices = tree.query(currentPoint, k=numberOfIntersections, distance_upper_bound=self.maxDistance, n_jobs=-1)

        print(nextPointsIndices)

        # If the current point is part of more trajectories,
        # an intersection happened. Call subroutine to part
        # the trajectories
        if numberOfIntersections &gt; 1:
            for j in range(0, len(self.trajectoryIndices[i])):
                trajIndex = self.trajectoryIndices[i][j]
                self.trajectoryIndices[i + 1 + nextPointsIndices[j]].append(trajIndex)

        else:
            self.trajectoryIndices[i + 1 + nextPointsIndices].append(self.trajectoryIndices[i][0])

        print(self.trajectoryIndices)
        &#39;&#39;&#39;</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.TrajectorySeparation.getTrajectories"><code class="name flex">
<span>def <span class="ident">getTrajectories</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getTrajectories(self):

    self.individualTrajectories = []
    for trajCentres in self.centresIndices:
        self.individualTrajectories.append(self.centres[trajCentres])

    self.individualTrajectories = np.array(self.individualTrajectories)
    return self.individualTrajectories

    &#39;&#39;&#39;
    self.individualTrajectories = [ [] for i in range(0, self.maxIndex + 1) ]
    for i in range(0, len(self.trajectoryIndices)):
        for trajIndex in self.trajectoryIndices[i]:
            self.individualTrajectories[trajIndex].append(self.centres[i])

    self.individualTrajectories = np.array(self.individualTrajectories)
    for i in range(len(self.individualTrajectories)):
        if len(self.individualTrajectories[i]) &gt; 0:
            self.individualTrajectories[i] = np.vstack(self.individualTrajectories[i])
    return self.individualTrajectories
    &#39;&#39;&#39;</code></pre>
</details>
</dd>
<dt id="pept.tracking.peptml.peptml.TrajectorySeparation.plotTrajectoriesAltAxes"><code class="name flex">
<span>def <span class="ident">plotTrajectoriesAltAxes</span></span>(<span>self, ax)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def plotTrajectoriesAltAxes(self, ax):
    trajectories = self.getTrajectories()
    for traj in trajectories:
        if len(traj) &gt; 0:
            ax.scatter(traj[:, 3], traj[:, 1], traj[:, 2], marker=&#39;D&#39;, s=10)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pept.tracking.peptml" href="index.html">pept.tracking.peptml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.findMeanError" href="#pept.tracking.peptml.peptml.findMeanError">findMeanError</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.ClusterCentres" href="#pept.tracking.peptml.peptml.ClusterCentres">ClusterCentres</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.ClusterCentres.getCentresSampleN" href="#pept.tracking.peptml.peptml.ClusterCentres.getCentresSampleN">getCentresSampleN</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClusterCentres.getNumberOfSamples" href="#pept.tracking.peptml.peptml.ClusterCentres.getNumberOfSamples">getNumberOfSamples</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.ClustererBase" href="#pept.tracking.peptml.peptml.ClustererBase">ClustererBase</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.getCentres" href="#pept.tracking.peptml.peptml.ClustererBase.getCentres">getCentres</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.getCentresTrace" href="#pept.tracking.peptml.peptml.ClustererBase.getCentresTrace">getCentresTrace</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.getLabels" href="#pept.tracking.peptml.peptml.ClustererBase.getLabels">getLabels</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.getSampleLabels" href="#pept.tracking.peptml.peptml.ClustererBase.getSampleLabels">getSampleLabels</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.getSampleLabelsTraces" href="#pept.tracking.peptml.peptml.ClustererBase.getSampleLabelsTraces">getSampleLabelsTraces</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.plotCentres" href="#pept.tracking.peptml.peptml.ClustererBase.plotCentres">plotCentres</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.plotCentresAltAxes" href="#pept.tracking.peptml.peptml.ClustererBase.plotCentresAltAxes">plotCentresAltAxes</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.plotSampleLabels" href="#pept.tracking.peptml.peptml.ClustererBase.plotSampleLabels">plotSampleLabels</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.ClustererBase.plotSampleLabelsAltAxes" href="#pept.tracking.peptml.peptml.ClustererBase.plotSampleLabelsAltAxes">plotSampleLabelsAltAxes</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.Cutpoints" href="#pept.tracking.peptml.peptml.Cutpoints">Cutpoints</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.Cutpoints.find_cutpoints" href="#pept.tracking.peptml.peptml.Cutpoints.find_cutpoints">find_cutpoints</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.Cutpoints.find_cutpoints_sample" href="#pept.tracking.peptml.peptml.Cutpoints.find_cutpoints_sample">find_cutpoints_sample</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.Cutpoints.get_cutoffs" href="#pept.tracking.peptml.peptml.Cutpoints.get_cutoffs">get_cutoffs</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer" href="#pept.tracking.peptml.peptml.HDBSCANClusterer">HDBSCANClusterer</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.allow_single_cluster" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.allow_single_cluster">allow_single_cluster</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.clusterIterable" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.clusterIterable">clusterIterable</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.clusterer" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.clusterer">clusterer</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.fitSampleParallel" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.fitSampleParallel">fitSampleParallel</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.fit_cutpoints" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.fit_cutpoints">fit_cutpoints</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.fit_sample" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.fit_sample">fit_sample</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.min_cluster_size" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.min_cluster_size">min_cluster_size</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANClusterer.min_samples" href="#pept.tracking.peptml.peptml.HDBSCANClusterer.min_samples">min_samples</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.HDBSCANclustererAuto" href="#pept.tracking.peptml.peptml.HDBSCANclustererAuto">HDBSCANclustererAuto</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANclustererAuto.changeParameters" href="#pept.tracking.peptml.peptml.HDBSCANclustererAuto.changeParameters">changeParameters</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANclustererAuto.fitSample" href="#pept.tracking.peptml.peptml.HDBSCANclustererAuto.fitSample">fitSample</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer">HDBSCANtwoPassClusterer</a></code></h4>
<ul class="two-column">
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.fit" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.fit">fit</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres">getCentres</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres2" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.getCentres2">getCentres2</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres">plotCentres</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2">plotCentres2</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2AltAxes" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentres2AltAxes">plotCentres2AltAxes</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentresAltAxes" href="#pept.tracking.peptml.peptml.HDBSCANtwoPassClusterer.plotCentresAltAxes">plotCentresAltAxes</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher" href="#pept.tracking.peptml.peptml.PlotlyGrapher">PlotlyGrapher</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTrace" href="#pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTrace">addDataAsTrace</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceColorbar" href="#pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceColorbar">addDataAsTraceColorbar</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceLine" href="#pept.tracking.peptml.peptml.PlotlyGrapher.addDataAsTraceLine">addDataAsTraceLine</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.addTrace" href="#pept.tracking.peptml.peptml.PlotlyGrapher.addTrace">addTrace</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.addTraces" href="#pept.tracking.peptml.peptml.PlotlyGrapher.addTraces">addTraces</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.createFigure" href="#pept.tracking.peptml.peptml.PlotlyGrapher.createFigure">createFigure</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.getFigure" href="#pept.tracking.peptml.peptml.PlotlyGrapher.getFigure">getFigure</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.PlotlyGrapher.showFigure" href="#pept.tracking.peptml.peptml.PlotlyGrapher.showFigure">showFigure</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pept.tracking.peptml.peptml.TrajectorySeparation" href="#pept.tracking.peptml.peptml.TrajectorySeparation">TrajectorySeparation</a></code></h4>
<ul class="">
<li><code><a title="pept.tracking.peptml.peptml.TrajectorySeparation.findTrajectories" href="#pept.tracking.peptml.peptml.TrajectorySeparation.findTrajectories">findTrajectories</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.TrajectorySeparation.getTrajectories" href="#pept.tracking.peptml.peptml.TrajectorySeparation.getTrajectories">getTrajectories</a></code></li>
<li><code><a title="pept.tracking.peptml.peptml.TrajectorySeparation.plotTrajectoriesAltAxes" href="#pept.tracking.peptml.peptml.TrajectorySeparation.plotTrajectoriesAltAxes">plotTrajectoriesAltAxes</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>